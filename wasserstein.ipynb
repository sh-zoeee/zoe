{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import ot\n",
    "\n",
    "from scripts import w_pq_batch as w_pq\n",
    "from scripts import trees, pq_gram, func\n",
    "\n",
    "from pqgrams.PQGram import Profile\n",
    "import pyconll\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EWT,Atis間のWasserstein距離"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensors_path = \"data/train_tensors_en_corpora_En_EWT_Atis_unlabel_50.pt\"\n",
    "train_labels_path = \"data/train_labels_en_corpora_En_EWT_Atis_unlabel_50.pt\"\n",
    "train_indexes_path = \"data/train_indexes_en_corpora_En_EWT_Atis_unlabel_50.pt\"\n",
    "\n",
    "valid_tensors_path = \"data/valid_tensors_en_corpora_En_EWT_Atis_unlabel_50.pt\"\n",
    "valid_labels_path = \"data/valid_labels_en_corpora_En_EWT_Atis_unlabel_50.pt\"\n",
    "valid_indexes_path = \"data/valid_indexes_en_corpora_En_EWT_Atis_unlabel_50.pt\"\n",
    "\n",
    "test_tensors_path = \"data/test_tensors_en_corpora_En_EWT_Atis_unlabel_50.pt\"\n",
    "test_labels_path = \"data/test_labels_en_corpora_En_EWT_Atis_unlabel_50.pt\"\n",
    "test_indexes_path = \"data/test_indexes_en_corpora_En_EWT_Atis_unlabel_50.pt\"\n",
    "\n",
    "model_path = \"models/model_en_corpora_EWT_Atis_unlabel_50.pth\"\n",
    "\n",
    "CoNLLU_EWT_PATH = \"corpora/English-EWT.conllu\"\n",
    "CoNLLU = pyconll.load_from_file(CoNLLU_EWT_PATH)\n",
    "EWT_tree_count = len(CoNLLU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CoNLLU_GPT_PATH = \"corpora/English-chatGPT.conllu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[convert tensor]: 100%|██████████| 30015/30015 [00:00<00:00, 41490.56it/s]\n"
     ]
    }
   ],
   "source": [
    "CoNLLU += pyconll.load_from_file(CoNLLU_GPT_PATH)\n",
    "\n",
    "\n",
    "PQ_Trees = [trees.conllTree_to_pqTree_unlabeled(conll.to_tree()) for conll in CoNLLU]\n",
    "PQ_Index = [Profile(tree, p=2, q=2) for tree in PQ_Trees]\n",
    "\n",
    "J = set(PQ_Index[0])\n",
    "for pq_set  in PQ_Index[1:]:\n",
    "    J = J.union(pq_set)\n",
    "J = list(J)\n",
    "\n",
    "tensors = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index, desc=\"[convert tensor]\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_distance_weighted(data1, data2, weights):\n",
    "    # 重みを適用\n",
    "    weights = func.softplus(weights)\n",
    "    weighted_data1 = [t*weights for t in data1]  # 各サンプルに重みを適用\n",
    "    weighted_data2 = [t*weights for t in data2]\n",
    "\n",
    "    distances = []\n",
    "    for dim in range(weighted_data1[0].size(0)):  # 8次元でループ\n",
    "        # dim次元の要素を全て取得して連結\n",
    "        x_dim = torch.cat([t[dim].unsqueeze(0) for t in weighted_data1])\n",
    "        y_dim = torch.cat([t[dim].unsqueeze(0) for t in weighted_data2])\n",
    "\n",
    "        # 次元ごとに要素をソート\n",
    "        x_sorted = torch.sort(x_dim)[0]\n",
    "        y_sorted = torch.sort(y_dim)[0]\n",
    "\n",
    "        # 累積分布関数 (CDF) を計算\n",
    "        cdf_x = torch.cumsum(torch.ones_like(x_sorted) / len(x_sorted), dim=0)\n",
    "        cdf_y = torch.cumsum(torch.ones_like(y_sorted) / len(y_sorted), dim=0)\n",
    "\n",
    "        # 各次元のWasserstein距離を計算\n",
    "        distance = torch.mean(torch.abs(cdf_x - cdf_y))\n",
    "        distances.append(distance)\n",
    "\n",
    "    print(distances)\n",
    "    # 各次元の距離の平均を返す\n",
    "    return torch.mean(torch.tensor(distances)).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WeightedPqgramDistance()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "distance_function = w_pq.WeightedPqgramDistance(tensors[0].size(), [], [])\n",
    "distance_function.load_state_dict(torch.load(model_path))\n",
    "distance_function.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = distance_function.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13394\n"
     ]
    }
   ],
   "source": [
    "print(min(EWT_tree_count, len(tensors)-EWT_tree_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors_EWT = tensors[:EWT_tree_count]\n",
    "tensors_GPT = tensors[EWT_tree_count:]\n",
    "sample_size = min(EWT_tree_count, len(tensors)-EWT_tree_count)\n",
    "if EWT_tree_count<sample_size:\n",
    "    tensors_GPT = random.sample(tensors_GPT, k=sample_size)\n",
    "else :\n",
    "    tensors_EWT = random.sample(tensors_EWT, k=sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensors_EWT = torch.zeros((EWT_tree_count,8))\n",
    "for i, tensor in enumerate(tensors_EWT):\n",
    "    Tensors_EWT[i] = tensor\n",
    "\n",
    "Tensors_GPT = torch.zeros((len(tensors_GPT),8))\n",
    "for i, tensor in enumerate(tensors_GPT):\n",
    "    Tensors_GPT[i] = tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_matrix_chunked(tensors: np.ndarray, weights: np.ndarray, chunk_size: int):\n",
    "    \"\"\"\n",
    "    データをチャンクに分割して距離行列を計算する関数。\n",
    "    tensors: 入力データ [N, dim] の配列\n",
    "    weights: 重み [dim] の配列\n",
    "    chunk_size: 一度に処理するデータのチャンクサイズ\n",
    "    \"\"\"\n",
    "\n",
    "    num_samples = tensors.shape[0]\n",
    "    dist_mat = np.zeros((num_samples, num_samples))  # 距離行列の初期化\n",
    "    \n",
    "    # チャンクごとに計算\n",
    "    for i in tqdm(range(0, num_samples, chunk_size)):\n",
    "        end_i = min(i + chunk_size, num_samples)\n",
    "        tensor_chunk_i = tensors[i:end_i, np.newaxis]  # [chunk_size, 1, dim]\n",
    "\n",
    "        for j in range(0, num_samples, chunk_size):\n",
    "            end_j = min(j + chunk_size, num_samples)\n",
    "            tensor_chunk_j = tensors[j:end_j, np.newaxis]  # [1, chunk_size, dim]\n",
    "            \n",
    "            # 差の計算\n",
    "            diff = np.abs(tensor_chunk_i - tensor_chunk_j)  # [chunk_size, chunk_size, dim]\n",
    "            aw = np.log1p(np.exp(weights))  # weightsのSoftplus関数を近似\n",
    "            aw = aw[np.newaxis, np.newaxis, :]  # [1, 1, dim]\n",
    "            weighted_diff = diff * aw  # アダマール積\n",
    "            dist_chunk = weighted_diff.sum(axis=2)  # 距離の計算\n",
    "            \n",
    "            # 距離行列に結果を格納\n",
    "            dist_mat[i:end_i, j:end_j] = dist_chunk\n",
    "\n",
    "    return dist_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16621\n"
     ]
    }
   ],
   "source": [
    "array_EWT = Tensors_EWT.numpy()\n",
    "array_GPT = Tensors_GPT.numpy()\n",
    "\n",
    "weights_np = weights.detach().numpy()\n",
    "\n",
    "array_size = len(array_EWT) + len(array_GPT)\n",
    "\n",
    "array_all = np.zeros((array_size, 8))\n",
    "\n",
    "print(len(array_EWT))\n",
    "\n",
    "for i in range(len(array_EWT)):\n",
    "    array_all[i] = array_EWT[i]\n",
    "\n",
    "for i in range(len(array_GPT)):\n",
    "    array_all[i+len(array_GPT)] = array_GPT[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_matrix_chunked(tensors: torch.Tensor, weights: torch.Tensor, chunk_size: int):\n",
    "    \"\"\"\n",
    "    データをチャンクに分割して距離行列を計算する関数。\n",
    "    tensors: 入力データ [N, dim] のテンソル\n",
    "    weights: 重み [dim] のテンソル\n",
    "    chunk_size: 一度に処理するデータのチャンクサイズ\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    num_samples = tensors.shape[0]\n",
    "    dist_mat = torch.zeros((num_samples, num_samples), device=device)  # 距離行列の初期化\n",
    "    \n",
    "    # チャンクごとに計算\n",
    "    for i in range(0, num_samples, chunk_size):\n",
    "        end_i = min(i + chunk_size, num_samples)\n",
    "        tensor_chunk_i = tensors[i:end_i].unsqueeze(1)  # [chunk_size, 1, dim]\n",
    "\n",
    "        for j in range(0, num_samples, chunk_size):\n",
    "            end_j = min(j + chunk_size, num_samples)\n",
    "            tensor_chunk_j = tensors[j:end_j].unsqueeze(0)  # [1, chunk_size, dim]\n",
    "            \n",
    "            # 差の計算\n",
    "            diff = torch.abs(tensor_chunk_i - tensor_chunk_j).to(device)  # [chunk_size, chunk_size, dim]\n",
    "            aw = func.softplus(weights).to(device).unsqueeze(0).unsqueeze(0)  # [1, 1, dim]\n",
    "            weighted_diff = diff * aw  # アダマール積\n",
    "            dist_chunk = weighted_diff.sum(dim=2)  # 距離の計算\n",
    "            \n",
    "            # 距離行列に結果を格納\n",
    "            dist_mat[i:end_i, j:end_j] = dist_chunk\n",
    "        del dist_chunk, end_j, aw, weighted_diff\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    del tensors, end_i\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return dist_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 3 has a total capacity of 23.65 GiB of which 3.19 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 21.73 GiB is allocated by PyTorch, and 1.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m distance_matrix\u001b[38;5;241m=\u001b[39m\u001b[43mdistance_matrix_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_all\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "Cell \u001b[0;32mIn[14], line 25\u001b[0m, in \u001b[0;36mdistance_matrix_chunked\u001b[0;34m(tensors, weights, chunk_size)\u001b[0m\n\u001b[1;32m     23\u001b[0m diff \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs(tensor_chunk_i \u001b[38;5;241m-\u001b[39m tensor_chunk_j)\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# [chunk_size, chunk_size, dim]\u001b[39;00m\n\u001b[1;32m     24\u001b[0m aw \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39msoftplus(weights)\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# [1, 1, dim]\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m weighted_diff \u001b[38;5;241m=\u001b[39m \u001b[43mdiff\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43maw\u001b[49m  \u001b[38;5;66;03m# アダマール積\u001b[39;00m\n\u001b[1;32m     26\u001b[0m dist_chunk \u001b[38;5;241m=\u001b[39m weighted_diff\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# 距離の計算\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# 距離行列に結果を格納\u001b[39;00m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 3 has a total capacity of 23.65 GiB of which 3.19 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 21.73 GiB is allocated by PyTorch, and 1.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "distance_matrix=distance_matrix_chunked(torch.from_numpy(array_all), weights, len(tensors)//512)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = np.zeros((array_size,array_size))\n",
    "\n",
    "for i in tqdm(range(array_size)):\n",
    "    for j in range(array_size):\n",
    "        dist = weighted\n",
    "        distance_matrix[i][j] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/129 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (234,1,8) (63,1,8) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdistance_matrix_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marray_all\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 22\u001b[0m, in \u001b[0;36mdistance_matrix_chunked\u001b[0;34m(tensors, weights, chunk_size)\u001b[0m\n\u001b[1;32m     19\u001b[0m tensor_chunk_j \u001b[38;5;241m=\u001b[39m tensors[j:end_j, np\u001b[38;5;241m.\u001b[39mnewaxis]  \u001b[38;5;66;03m# [1, chunk_size, dim]\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# 差の計算\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m diff \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(\u001b[43mtensor_chunk_i\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtensor_chunk_j\u001b[49m)  \u001b[38;5;66;03m# [chunk_size, chunk_size, dim]\u001b[39;00m\n\u001b[1;32m     23\u001b[0m aw \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog1p(np\u001b[38;5;241m.\u001b[39mexp(weights))  \u001b[38;5;66;03m# weightsのSoftplus関数を近似\u001b[39;00m\n\u001b[1;32m     24\u001b[0m aw \u001b[38;5;241m=\u001b[39m aw[np\u001b[38;5;241m.\u001b[39mnewaxis, np\u001b[38;5;241m.\u001b[39mnewaxis, :]  \u001b[38;5;66;03m# [1, 1, dim]\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (234,1,8) (63,1,8) "
     ]
    }
   ],
   "source": [
    "distance_matrix_chunked(array_all, weights_np, len(array_all)//128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_matrix(data, distance_func):\n",
    "    num_points = data.shape[0]\n",
    "    cost_matrix = np.zeros((num_points, num_points))\n",
    "\n",
    "    for i in range(num_points):\n",
    "        for j in range(num_points):\n",
    "            if i != j:\n",
    "                cost_matrix[i, j] = distance_func(data[i], data[j])\n",
    "    \n",
    "    return cost_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_matrix = compute_cost_matrix(data_a, custom_distance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
