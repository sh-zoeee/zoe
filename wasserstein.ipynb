{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, distance\n",
    "import numpy as np\n",
    "\n",
    "import ot\n",
    "\n",
    "from scripts import w_pq_batch as w_pq\n",
    "from scripts import trees, pq_gram, func\n",
    "\n",
    "from pqgrams.PQGram import Profile\n",
    "import pyconll, zss\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 8, 9, 10, 11, 12, 13, 14, 15] [1, 2, 3] [4, 5, 6]\n",
      "[1, 2, 3, 10, 11, 12, 13, 14, 15] [4, 5, 6] [7, 8, 9]\n",
      "[1, 2, 3, 4, 5, 6, 13, 14, 15] [7, 8, 9] [10, 11, 12]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9] [10, 11, 12] [13, 14, 15]\n",
      "[4, 5, 6, 7, 8, 9, 10, 11, 12] [13, 14, 15] [1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "x = [[1,2,3], [4,5,6], [7,8,9], [10,11,12], [13,14,15]]\n",
    "sup = len(x)\n",
    "\n",
    "for i in range(sup):\n",
    "    tmp = x.copy()\n",
    "    val = tmp.pop(i)\n",
    "    tes = tmp.pop(i%len(tmp))\n",
    "    tra = sum(tmp, [])\n",
    "    print(tra, val, tes)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EWT,Atis間のWasserstein距離"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensors_path = \"data/train_tensors_en_corpora_En_EWT_Atis_unlabel_50.pt\"\n",
    "train_labels_path = \"data/train_labels_en_corpora_En_EWT_Atis_unlabel_50.pt\"\n",
    "train_indexes_path = \"data/train_indexes_en_corpora_En_EWT_Atis_unlabel_50.pt\"\n",
    "\n",
    "valid_tensors_path = \"data/valid_tensors_en_corpora_En_EWT_Atis_unlabel_50.pt\"\n",
    "valid_labels_path = \"data/valid_labels_en_corpora_En_EWT_Atis_unlabel_50.pt\"\n",
    "valid_indexes_path = \"data/valid_indexes_en_corpora_En_EWT_Atis_unlabel_50.pt\"\n",
    "\n",
    "test_tensors_path = \"data/test_tensors_en_corpora_En_EWT_Atis_unlabel_50.pt\"\n",
    "test_labels_path = \"data/test_labels_en_corpora_En_EWT_Atis_unlabel_50.pt\"\n",
    "test_indexes_path = \"data/test_indexes_en_corpora_En_EWT_Atis_unlabel_50.pt\"\n",
    "\n",
    "model_path = \"models/model_en_corpora_EWT_Atis_unlabel_50.pth\"\n",
    "\n",
    "CoNLLU_EWT_PATH = \"corpora/English-EWT.conllu\"\n",
    "CoNLLU = pyconll.load_from_file(CoNLLU_EWT_PATH)\n",
    "EWT_tree_count = len(CoNLLU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensors = torch.load(train_tensors_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-2.0425, -2.2598, -1.7006, -2.2871, -2.0425,  0.3741, -1.7006, -1.7006],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_function = w_pq.WeightedPqgramDistance(train_tensors[0].size(), [], [])\n",
    "distance_function.load_state_dict(torch.load(model_path))\n",
    "distance_function.eval()\n",
    "weights = distance_function.weights\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OTマトリックス: 0.39999999999999997\n"
     ]
    }
   ],
   "source": [
    "a = [0.3, 0.7]  # ソース分布（サイズ2）\n",
    "b = [0.4, 0.4, 0.2]  # ターゲット分布（サイズ3）\n",
    "M = [[0.0, 1.0, 2.0],  # 2x3 のコスト行列\n",
    "     [1.0, 0.5, 0.5]]\n",
    "\n",
    "T = ot.emd2(a, b, M)\n",
    "print(\"OTマトリックス:\", T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CoNLLU_GPT_PATH = \"corpora/English-chatGPT.conllu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[convert tensor]: 100%|██████████| 30015/30015 [00:00<00:00, 41490.56it/s]\n"
     ]
    }
   ],
   "source": [
    "CoNLLU += pyconll.load_from_file(CoNLLU_GPT_PATH)\n",
    "\n",
    "\n",
    "PQ_Trees = [trees.conllTree_to_pqTree_unlabeled(conll.to_tree()) for conll in CoNLLU]\n",
    "PQ_Index = [Profile(tree, p=2, q=2) for tree in PQ_Trees]\n",
    "\n",
    "J = set(PQ_Index[0])\n",
    "for pq_set  in PQ_Index[1:]:\n",
    "    J = J.union(pq_set)\n",
    "J = list(J)\n",
    "\n",
    "tensors = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index, desc=\"[convert tensor]\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_distance_weighted(data1, data2, weights):\n",
    "    # 重みを適用\n",
    "    weights = func.softplus(weights)\n",
    "    weighted_data1 = [t*weights for t in data1]  # 各サンプルに重みを適用\n",
    "    weighted_data2 = [t*weights for t in data2]\n",
    "\n",
    "    distances = []\n",
    "    for dim in range(weighted_data1[0].size(0)):  # 8次元でループ\n",
    "        # dim次元の要素を全て取得して連結\n",
    "        x_dim = torch.cat([t[dim].unsqueeze(0) for t in weighted_data1])\n",
    "        y_dim = torch.cat([t[dim].unsqueeze(0) for t in weighted_data2])\n",
    "\n",
    "        # 次元ごとに要素をソート\n",
    "        x_sorted = torch.sort(x_dim)[0]\n",
    "        y_sorted = torch.sort(y_dim)[0]\n",
    "\n",
    "        # 累積分布関数 (CDF) を計算\n",
    "        cdf_x = torch.cumsum(torch.ones_like(x_sorted) / len(x_sorted), dim=0)\n",
    "        cdf_y = torch.cumsum(torch.ones_like(y_sorted) / len(y_sorted), dim=0)\n",
    "\n",
    "        # 各次元のWasserstein距離を計算\n",
    "        distance = torch.mean(torch.abs(cdf_x - cdf_y))\n",
    "        distances.append(distance)\n",
    "\n",
    "    print(distances)\n",
    "    # 各次元の距離の平均を返す\n",
    "    return torch.mean(torch.tensor(distances)).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WeightedPqgramDistance()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_function = w_pq.WeightedPqgramDistance(tensors[0].size(), [], [])\n",
    "distance_function.load_state_dict(torch.load(model_path))\n",
    "distance_function.eval()\n",
    "weights = distance_function.weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = distance_function.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13394\n"
     ]
    }
   ],
   "source": [
    "print(min(EWT_tree_count, len(tensors)-EWT_tree_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors_EWT = tensors[:EWT_tree_count]\n",
    "tensors_GPT = tensors[EWT_tree_count:]\n",
    "sample_size = min(EWT_tree_count, len(tensors)-EWT_tree_count)\n",
    "if EWT_tree_count<sample_size:\n",
    "    tensors_GPT = random.sample(tensors_GPT, k=sample_size)\n",
    "else :\n",
    "    tensors_EWT = random.sample(tensors_EWT, k=sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensors_EWT = torch.zeros((EWT_tree_count,8))\n",
    "for i, tensor in enumerate(tensors_EWT):\n",
    "    Tensors_EWT[i] = tensor\n",
    "\n",
    "Tensors_GPT = torch.zeros((len(tensors_GPT),8))\n",
    "for i, tensor in enumerate(tensors_GPT):\n",
    "    Tensors_GPT[i] = tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_matrix_chunked(tensors: np.ndarray, weights: np.ndarray, chunk_size: int):\n",
    "    \"\"\"\n",
    "    データをチャンクに分割して距離行列を計算する関数。\n",
    "    tensors: 入力データ [N, dim] の配列\n",
    "    weights: 重み [dim] の配列\n",
    "    chunk_size: 一度に処理するデータのチャンクサイズ\n",
    "    \"\"\"\n",
    "\n",
    "    num_samples = tensors.shape[0]\n",
    "    dist_mat = np.zeros((num_samples, num_samples))  # 距離行列の初期化\n",
    "    \n",
    "    # チャンクごとに計算\n",
    "    for i in tqdm(range(0, num_samples, chunk_size)):\n",
    "        end_i = min(i + chunk_size, num_samples)\n",
    "        tensor_chunk_i = tensors[i:end_i, np.newaxis]  # [chunk_size, 1, dim]\n",
    "\n",
    "        for j in range(0, num_samples, chunk_size):\n",
    "            end_j = min(j + chunk_size, num_samples)\n",
    "            tensor_chunk_j = tensors[j:end_j, np.newaxis]  # [1, chunk_size, dim]\n",
    "            \n",
    "            # 差の計算\n",
    "            diff = np.abs(tensor_chunk_i - tensor_chunk_j)  # [chunk_size, chunk_size, dim]\n",
    "            aw = np.log1p(np.exp(weights))  # weightsのSoftplus関数を近似\n",
    "            aw = aw[np.newaxis, np.newaxis, :]  # [1, 1, dim]\n",
    "            weighted_diff = diff * aw  # アダマール積\n",
    "            dist_chunk = weighted_diff.sum(axis=2)  # 距離の計算\n",
    "            \n",
    "            # 距離行列に結果を格納\n",
    "            dist_mat[i:end_i, j:end_j] = dist_chunk\n",
    "\n",
    "    return dist_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16621\n"
     ]
    }
   ],
   "source": [
    "array_EWT = Tensors_EWT.numpy()\n",
    "array_GPT = Tensors_GPT.numpy()\n",
    "\n",
    "weights_np = weights.detach().numpy()\n",
    "\n",
    "array_size = len(array_EWT) + len(array_GPT)\n",
    "\n",
    "array_all = np.zeros((array_size, 8))\n",
    "\n",
    "print(len(array_EWT))\n",
    "\n",
    "for i in range(len(array_EWT)):\n",
    "    array_all[i] = array_EWT[i]\n",
    "\n",
    "for i in range(len(array_GPT)):\n",
    "    array_all[i+len(array_GPT)] = array_GPT[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_matrix_chunked(tensors: torch.Tensor, weights: torch.Tensor, chunk_size: int):\n",
    "    \"\"\"\n",
    "    データをチャンクに分割して距離行列を計算する関数。\n",
    "    tensors: 入力データ [N, dim] のテンソル\n",
    "    weights: 重み [dim] のテンソル\n",
    "    chunk_size: 一度に処理するデータのチャンクサイズ\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    num_samples = tensors.shape[0]\n",
    "    dist_mat = torch.zeros((num_samples, num_samples), device=device)  # 距離行列の初期化\n",
    "    \n",
    "    # チャンクごとに計算\n",
    "    for i in range(0, num_samples, chunk_size):\n",
    "        end_i = min(i + chunk_size, num_samples)\n",
    "        tensor_chunk_i = tensors[i:end_i].unsqueeze(1)  # [chunk_size, 1, dim]\n",
    "\n",
    "        for j in range(0, num_samples, chunk_size):\n",
    "            end_j = min(j + chunk_size, num_samples)\n",
    "            tensor_chunk_j = tensors[j:end_j].unsqueeze(0)  # [1, chunk_size, dim]\n",
    "            \n",
    "            # 差の計算\n",
    "            diff = torch.abs(tensor_chunk_i - tensor_chunk_j).to(device)  # [chunk_size, chunk_size, dim]\n",
    "            aw = func.softplus(weights).to(device).unsqueeze(0).unsqueeze(0)  # [1, 1, dim]\n",
    "            weighted_diff = diff * aw  # アダマール積\n",
    "            dist_chunk = weighted_diff.sum(dim=2)  # 距離の計算\n",
    "            \n",
    "            # 距離行列に結果を格納\n",
    "            dist_mat[i:end_i, j:end_j] = dist_chunk\n",
    "        del dist_chunk, end_j, aw, weighted_diff\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    del tensors, end_i\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return dist_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 3 has a total capacity of 23.65 GiB of which 3.19 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 21.73 GiB is allocated by PyTorch, and 1.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m distance_matrix\u001b[38;5;241m=\u001b[39m\u001b[43mdistance_matrix_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_all\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "Cell \u001b[0;32mIn[14], line 25\u001b[0m, in \u001b[0;36mdistance_matrix_chunked\u001b[0;34m(tensors, weights, chunk_size)\u001b[0m\n\u001b[1;32m     23\u001b[0m diff \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs(tensor_chunk_i \u001b[38;5;241m-\u001b[39m tensor_chunk_j)\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# [chunk_size, chunk_size, dim]\u001b[39;00m\n\u001b[1;32m     24\u001b[0m aw \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39msoftplus(weights)\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# [1, 1, dim]\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m weighted_diff \u001b[38;5;241m=\u001b[39m \u001b[43mdiff\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43maw\u001b[49m  \u001b[38;5;66;03m# アダマール積\u001b[39;00m\n\u001b[1;32m     26\u001b[0m dist_chunk \u001b[38;5;241m=\u001b[39m weighted_diff\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# 距離の計算\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# 距離行列に結果を格納\u001b[39;00m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 3 has a total capacity of 23.65 GiB of which 3.19 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 21.73 GiB is allocated by PyTorch, and 1.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "distance_matrix=distance_matrix_chunked(torch.from_numpy(array_all), weights, len(tensors)//512)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = np.zeros((array_size,array_size))\n",
    "\n",
    "for i in tqdm(range(array_size)):\n",
    "    for j in range(array_size):\n",
    "        dist = weighted\n",
    "        distance_matrix[i][j] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/129 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (234,1,8) (63,1,8) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdistance_matrix_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marray_all\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 22\u001b[0m, in \u001b[0;36mdistance_matrix_chunked\u001b[0;34m(tensors, weights, chunk_size)\u001b[0m\n\u001b[1;32m     19\u001b[0m tensor_chunk_j \u001b[38;5;241m=\u001b[39m tensors[j:end_j, np\u001b[38;5;241m.\u001b[39mnewaxis]  \u001b[38;5;66;03m# [1, chunk_size, dim]\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# 差の計算\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m diff \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(\u001b[43mtensor_chunk_i\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtensor_chunk_j\u001b[49m)  \u001b[38;5;66;03m# [chunk_size, chunk_size, dim]\u001b[39;00m\n\u001b[1;32m     23\u001b[0m aw \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog1p(np\u001b[38;5;241m.\u001b[39mexp(weights))  \u001b[38;5;66;03m# weightsのSoftplus関数を近似\u001b[39;00m\n\u001b[1;32m     24\u001b[0m aw \u001b[38;5;241m=\u001b[39m aw[np\u001b[38;5;241m.\u001b[39mnewaxis, np\u001b[38;5;241m.\u001b[39mnewaxis, :]  \u001b[38;5;66;03m# [1, 1, dim]\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (234,1,8) (63,1,8) "
     ]
    }
   ],
   "source": [
    "distance_matrix_chunked(array_all, weights_np, len(array_all)//128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_matrix(data, distance_func):\n",
    "    num_points = data.shape[0]\n",
    "    cost_matrix = np.zeros((num_points, num_points))\n",
    "\n",
    "    for i in range(num_points):\n",
    "        for j in range(num_points):\n",
    "            if i != j:\n",
    "                cost_matrix[i, j] = distance_func(data[i], data[j])\n",
    "    \n",
    "    return cost_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_matrix = compute_cost_matrix(data_a, custom_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wasserstein距離の計測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### English-EWT, chatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CoNLLU_EWT_PATH = \"corpora/English-EWT.conllu\"\n",
    "CoNLLU = pyconll.load_from_file(CoNLLU_EWT_PATH)\n",
    "EWT_tree_count = len(CoNLLU)\n",
    "\n",
    "CoNLLU_GPT_PATH = \"corpora/English-chatGPT.conllu\"\n",
    "CoNLLU += pyconll.load_from_file(CoNLLU_GPT_PATH)\n",
    "GPT_tree_count = len(CoNLLU) - EWT_tree_count\n",
    "\n",
    "\n",
    "PQ_Trees = [trees.conllTree_to_pqTree_unlabeled(conll.to_tree()) for conll in CoNLLU]\n",
    "PQ_Index = [Profile(tree, p=2, q=2) for tree in PQ_Trees]\n",
    "\n",
    "J = set(PQ_Index[0])\n",
    "for pq_set  in PQ_Index[1:]:\n",
    "    J = J.union(pq_set)\n",
    "J = list(J)\n",
    "\n",
    "tensors_EWT = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[:EWT_tree_count], desc=\"[convert tensor]\")]\n",
    "tensors_GPT = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[EWT_tree_count:], desc=\"[convert tensor]\")]\n",
    "\n",
    "\n",
    "model_path = \"models/model_en_corpora_EWT_Atis_unlabel_50.pth\"\n",
    "distance_function = w_pq.WeightedPqgramDistance(tensors_EWT[0].size(), [], [])\n",
    "distance_function.load_state_dict(torch.load(model_path))\n",
    "distance_function.eval()\n",
    "weights = distance_function.weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for _ in range(EWT_tree_count):\n",
    "    a.append(1/EWT_tree_count)\n",
    "b = []\n",
    "for _ in range(GPT_tree_count):\n",
    "    b.append(1/GPT_tree_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2fb53123d74474a06c01f1462cf3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cost_matrix = torch.zeros((EWT_tree_count, GPT_tree_count))\n",
    "\n",
    "tensors_EWT = torch.stack([t.to(\"cuda\") for t in tensors_EWT])\n",
    "tensors_GPT = torch.stack([t.to(\"cuda\") for t in tensors_GPT])\n",
    "\n",
    "for i in tqdm(range(EWT_tree_count)):\n",
    "    t_ewt = tensors_EWT[i].unsqueeze(0)\n",
    "    cost_matrix[i] = w_pq.weighted_pqgram_distance_batch(weights, tensors_GPT, t_ewt.repeat(tensors_GPT.size(0), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5900653316080489"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ot.emd2(a, b, cost_matrix.detach().numpy(), numItermax=1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EWT - EWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163bc9a5ebba45c996c6df7a928af39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/16621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d94987be1c94453797f31e339f4425e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/16621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b39c6bf284e348f89236ba45f2379bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[cost matrix]:   0%|          | 0/16621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "CoNLLU_source_PATH = \"corpora/English/English-EWT.conllu\"\n",
    "CoNLLU = pyconll.load_from_file(CoNLLU_source_PATH)\n",
    "source_tree_count = len(CoNLLU)\n",
    "\n",
    "CoNLLU_target_PATH = \"corpora/English/English-EWT.conllu\"\n",
    "CoNLLU += pyconll.load_from_file(CoNLLU_target_PATH)\n",
    "target_tree_count = len(CoNLLU) - source_tree_count\n",
    "\n",
    "\n",
    "PQ_Trees = [trees.conllTree_to_pqTree_unlabeled(conll.to_tree()) for conll in CoNLLU]\n",
    "PQ_Index = [Profile(tree, p=2, q=2) for tree in PQ_Trees]\n",
    "\n",
    "J = set(PQ_Index[0])\n",
    "for pq_set  in PQ_Index[1:]:\n",
    "    J = J.union(pq_set)\n",
    "J = list(J)\n",
    "\n",
    "tensors_source = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[:source_tree_count], desc=\"[convert tensor]\")]\n",
    "tensors_target = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[source_tree_count:], desc=\"[convert tensor]\")]\n",
    "\n",
    "\n",
    "model_path = \"models/model_en_corpora_EWT_EWT_unlabel_50.pth\"\n",
    "distance_function = w_pq.WeightedPqgramDistance(tensors_source[0].size(), [], [])\n",
    "distance_function.load_state_dict(torch.load(model_path))\n",
    "distance_function.eval()\n",
    "weights = distance_function.weights\n",
    "\n",
    "a = []\n",
    "for _ in range(source_tree_count):\n",
    "    a.append(1/source_tree_count)\n",
    "b = []\n",
    "for _ in range(target_tree_count):\n",
    "    b.append(1/target_tree_count)\n",
    "\n",
    "cost_matrix = torch.zeros((source_tree_count, target_tree_count))\n",
    "\n",
    "tensors_source = torch.stack([t.to(\"cuda\") for t in tensors_source])\n",
    "tensors_target = torch.stack([t.to(\"cuda\") for t in tensors_target])\n",
    "\n",
    "for i in tqdm(range(source_tree_count), desc=\"[cost matrix]\"):\n",
    "    t_source = tensors_source[i].unsqueeze(0)\n",
    "    cost_matrix[i] = w_pq.weighted_pqgram_distance_batch(weights, tensors_target, t_source.repeat(tensors_target.size(0), 1))\n",
    "\n",
    "print(ot.emd2(a, b, cost_matrix.detach().numpy(), numItermax=1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EWT-ESL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16621 5124\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf8aa70444d24ad296ec53ae586a6e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/16621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45bd587937a041e1ad551c87be74dd9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/5124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f98d85d9ad6749deb353b83bdb9c9a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[cost matrix]:   0%|          | 0/16621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.9966181391755065\n"
     ]
    }
   ],
   "source": [
    "CoNLLU_source_PATH = \"corpora/English/English-EWT.conllu\"\n",
    "CoNLLU = pyconll.load_from_file(CoNLLU_source_PATH)\n",
    "source_tree_count = len(CoNLLU)\n",
    "\n",
    "CoNLLU_target_PATH = \"corpora/English/English-ESL.conllu\"\n",
    "CoNLLU += pyconll.load_from_file(CoNLLU_target_PATH)\n",
    "target_tree_count = len(CoNLLU) - source_tree_count\n",
    "\n",
    "print(source_tree_count, target_tree_count)\n",
    "\n",
    "PQ_Trees = [trees.conllTree_to_pqTree_unlabeled(conll.to_tree()) for conll in CoNLLU]\n",
    "PQ_Index = [Profile(tree, p=2, q=2) for tree in PQ_Trees]\n",
    "\n",
    "J = set(PQ_Index[0])\n",
    "for pq_set  in PQ_Index[1:]:\n",
    "    J = J.union(pq_set)\n",
    "J = list(J)\n",
    "\n",
    "tensors_source = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[:source_tree_count], desc=\"[convert tensor]\")]\n",
    "tensors_target = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[source_tree_count:], desc=\"[convert tensor]\")]\n",
    "\n",
    "\n",
    "model_path = \"models/model_en_corpora_En_EWT_ESL_unlabel_50.pth\"\n",
    "distance_function = w_pq.WeightedPqgramDistance(tensors_source[0].size(), [], [])\n",
    "distance_function.load_state_dict(torch.load(model_path))\n",
    "distance_function.eval()\n",
    "weights = distance_function.weights\n",
    "\n",
    "a = []\n",
    "for _ in range(source_tree_count):\n",
    "    a.append(1/source_tree_count)\n",
    "b = []\n",
    "for _ in range(target_tree_count):\n",
    "    b.append(1/target_tree_count)\n",
    "\n",
    "cost_matrix = torch.zeros((source_tree_count, target_tree_count))\n",
    "\n",
    "tensors_source = torch.stack([t.to(\"cuda:3\") for t in tensors_source])\n",
    "tensors_target = torch.stack([t.to(\"cuda:3\") for t in tensors_target])\n",
    "\n",
    "for i in tqdm(range(source_tree_count), desc=\"[cost matrix]\"):\n",
    "    t_source = tensors_source[i].unsqueeze(0)\n",
    "    cost_matrix[i] = w_pq.weighted_pqgram_distance_batch(weights, tensors_target, t_source.repeat(tensors_target.size(0), 1))\n",
    "\n",
    "print(ot.emd2(a, b, cost_matrix.detach().numpy(), numItermax=1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EWT - Atis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16621 5432\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c857dd22e5e140e4ab00ccd9fa908e1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/16621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01cfe25cb7ef4b2390aa718d04985d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/5432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0081260c081496ab575dc12197e8802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[cost matrix]:   0%|          | 0/16621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.267264440750935\n"
     ]
    }
   ],
   "source": [
    "CoNLLU_source_PATH = \"corpora/English/English-EWT.conllu\"\n",
    "CoNLLU = pyconll.load_from_file(CoNLLU_source_PATH)\n",
    "source_tree_count = len(CoNLLU)\n",
    "\n",
    "CoNLLU_target_PATH = \"corpora/English/English-Atis.conllu\"\n",
    "CoNLLU += pyconll.load_from_file(CoNLLU_target_PATH)\n",
    "target_tree_count = len(CoNLLU) - source_tree_count\n",
    "\n",
    "print(source_tree_count, target_tree_count)\n",
    "\n",
    "PQ_Trees = [trees.conllTree_to_pqTree_unlabeled(conll.to_tree()) for conll in CoNLLU]\n",
    "PQ_Index = [Profile(tree, p=2, q=2) for tree in PQ_Trees]\n",
    "\n",
    "J = set(PQ_Index[0])\n",
    "for pq_set  in PQ_Index[1:]:\n",
    "    J = J.union(pq_set)\n",
    "J = list(J)\n",
    "\n",
    "tensors_source = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[:source_tree_count], desc=\"[convert tensor]\")]\n",
    "tensors_target = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[source_tree_count:], desc=\"[convert tensor]\")]\n",
    "\n",
    "\n",
    "model_path = \"models/model_en_corpora_EWT_Atis_unlabel_50.pth\"\n",
    "distance_function = w_pq.WeightedPqgramDistance(tensors_source[0].size(), [], [])\n",
    "distance_function.load_state_dict(torch.load(model_path))\n",
    "distance_function.eval()\n",
    "weights = distance_function.weights\n",
    "\n",
    "a = []\n",
    "for _ in range(source_tree_count):\n",
    "    a.append(1/source_tree_count)\n",
    "b = []\n",
    "for _ in range(target_tree_count):\n",
    "    b.append(1/target_tree_count)\n",
    "\n",
    "cost_matrix = torch.zeros((source_tree_count, target_tree_count))\n",
    "\n",
    "tensors_source = torch.stack([t.to(\"cuda:3\") for t in tensors_source])\n",
    "tensors_target = torch.stack([t.to(\"cuda:3\") for t in tensors_target])\n",
    "\n",
    "for i in tqdm(range(source_tree_count), desc=\"[cost matrix]\"):\n",
    "    t_source = tensors_source[i].unsqueeze(0)\n",
    "    cost_matrix[i] = w_pq.weighted_pqgram_distance_batch(weights, tensors_target, t_source.repeat(tensors_target.size(0), 1))\n",
    "\n",
    "print(ot.emd2(a, b, cost_matrix.detach().numpy(), numItermax=1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EWT - Ja-BCCWJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16621 16621\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c769e30a75e14ff39a46df36c21f467f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/16621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8df1dd2507f425ca95596d7bbff7123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/16621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc7f683a149408e8358e5265bf28b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[cost matrix]:   0%|          | 0/16621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9210620399488905\n"
     ]
    }
   ],
   "source": [
    "CoNLLU_source_PATH = \"corpora/English/English-EWT.conllu\"\n",
    "CoNLLU = pyconll.load_from_file(CoNLLU_source_PATH)\n",
    "source_tree_count = len(CoNLLU)\n",
    "\n",
    "CoNLLU_target_PATH = \"corpora/Japanese/Japanese-BCCWJ.conllu\"\n",
    "CoNLLU += random.sample(pyconll.load_from_file(CoNLLU_target_PATH), k=30000)\n",
    "target_tree_count = len(CoNLLU) - source_tree_count\n",
    "\n",
    "print(source_tree_count, target_tree_count)\n",
    "\n",
    "PQ_Trees = [trees.conllTree_to_pqTree_unlabeled(conll.to_tree()) for conll in CoNLLU]\n",
    "PQ_Index = [Profile(tree, p=2, q=2) for tree in PQ_Trees]\n",
    "\n",
    "J = set(PQ_Index[0])\n",
    "for pq_set  in PQ_Index[1:]:\n",
    "    J = J.union(pq_set)\n",
    "J = list(J)\n",
    "\n",
    "tensors_source = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[:source_tree_count], desc=\"[convert tensor]\")]\n",
    "tensors_target = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[source_tree_count:], desc=\"[convert tensor]\")]\n",
    "\n",
    "\n",
    "model_path = \"models/model_en_corpora_EWT_Ja-BCCWJ_unlabel_50.pth\"\n",
    "distance_function = w_pq.WeightedPqgramDistance(tensors_source[0].size(), [], [])\n",
    "distance_function.load_state_dict(torch.load(model_path))\n",
    "distance_function.eval()\n",
    "weights = distance_function.weights\n",
    "\n",
    "a = []\n",
    "for _ in range(source_tree_count):\n",
    "    a.append(1/source_tree_count)\n",
    "b = []\n",
    "for _ in range(target_tree_count):\n",
    "    b.append(1/target_tree_count)\n",
    "\n",
    "cost_matrix = torch.zeros((source_tree_count, target_tree_count))\n",
    "\n",
    "tensors_source = torch.stack([t.to(\"cuda:3\") for t in tensors_source])\n",
    "tensors_target = torch.stack([t.to(\"cuda:3\") for t in tensors_target])\n",
    "\n",
    "for i in tqdm(range(source_tree_count), desc=\"[cost matrix]\"):\n",
    "    t_source = tensors_source[i].unsqueeze(0)\n",
    "    cost_matrix[i] = w_pq.weighted_pqgram_distance_batch(weights, tensors_target, t_source.repeat(tensors_target.size(0), 1))\n",
    "\n",
    "print(ot.emd2(a, b, cost_matrix.detach().numpy(), numItermax=1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En-EWT -- Fr-GSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16621 14450\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ddf720c3ff438ba036db9bb1f10b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/16621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a53f2947fae4a76a0e5238951edd3e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/14450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6aaf70d8d245a5922747562864f842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[cost matrix]:   0%|          | 0/16621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.909186519127199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamazoe/.pyenv/versions/3.11.7/envs/env_pq/lib/python3.11/site-packages/ot/lp/__init__.py:580: UserWarning: numItermax reached before optimality. Try to increase numItermax.\n",
      "  check_result(result_code)\n"
     ]
    }
   ],
   "source": [
    "CoNLLU_source_PATH = \"corpora/English/English-EWT.conllu\"\n",
    "CoNLLU = pyconll.load_from_file(CoNLLU_source_PATH)\n",
    "source_tree_count = len(CoNLLU)\n",
    "\n",
    "CoNLLU_target_PATH = \"corpora/French/French-GSD.conllu\"\n",
    "CoNLLU += pyconll.load_from_file(CoNLLU_target_PATH)\n",
    "target_tree_count = len(CoNLLU) - source_tree_count\n",
    "\n",
    "print(source_tree_count, target_tree_count)\n",
    "\n",
    "PQ_Trees = [trees.conllTree_to_pqTree_unlabeled(conll.to_tree()) for conll in CoNLLU]\n",
    "PQ_Index = [Profile(tree, p=2, q=2) for tree in PQ_Trees]\n",
    "\n",
    "J = set(PQ_Index[0])\n",
    "for pq_set  in PQ_Index[1:]:\n",
    "    J = J.union(pq_set)\n",
    "J = list(J)\n",
    "\n",
    "tensors_source = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[:source_tree_count], desc=\"[convert tensor]\")]\n",
    "tensors_target = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[source_tree_count:], desc=\"[convert tensor]\")]\n",
    "\n",
    "\n",
    "model_path = \"models/model_En-EWT_Fr-GSD_unlabel_50.pth\"\n",
    "distance_function = w_pq.WeightedPqgramDistance(tensors_source[0].size(), [], [])\n",
    "distance_function.load_state_dict(torch.load(model_path))\n",
    "distance_function.eval()\n",
    "weights = distance_function.weights\n",
    "\n",
    "a = []\n",
    "for _ in range(source_tree_count):\n",
    "    a.append(1/source_tree_count)\n",
    "b = []\n",
    "for _ in range(target_tree_count):\n",
    "    b.append(1/target_tree_count)\n",
    "\n",
    "cost_matrix = torch.zeros((source_tree_count, target_tree_count))\n",
    "\n",
    "tensors_source = torch.stack([t.to(\"cuda:3\") for t in tensors_source])\n",
    "tensors_target = torch.stack([t.to(\"cuda:3\") for t in tensors_target])\n",
    "\n",
    "for i in tqdm(range(source_tree_count), desc=\"[cost matrix]\"):\n",
    "    t_source = tensors_source[i].unsqueeze(0)\n",
    "    cost_matrix[i] = w_pq.weighted_pqgram_distance_batch(weights, tensors_target, t_source.repeat(tensors_target.size(0), 1))\n",
    "\n",
    "print(ot.emd2(a, b, cost_matrix.detach().numpy(), numItermax=1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EWT -- Korean-Kaist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16621 23010\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4be19767d2a4e629f08701792af850b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/16621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33da7cb5580d416bbbfc3fdf8c5bbe14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/23010 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19237a6a9c0d4a3f9ed1dc67eaf163e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[cost matrix]:   0%|          | 0/16621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.889577513517188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamazoe/.pyenv/versions/3.11.7/envs/env_pq/lib/python3.11/site-packages/ot/lp/__init__.py:580: UserWarning: numItermax reached before optimality. Try to increase numItermax.\n",
      "  check_result(result_code)\n"
     ]
    }
   ],
   "source": [
    "CoNLLU_source_PATH = \"corpora/English/English-EWT.conllu\"\n",
    "CoNLLU = pyconll.load_from_file(CoNLLU_source_PATH)\n",
    "source_tree_count = len(CoNLLU)\n",
    "\n",
    "CoNLLU_target_PATH = \"corpora/Korean/Korean-Kaist.conllu\"\n",
    "CoNLLU += pyconll.load_from_file(CoNLLU_target_PATH)\n",
    "target_tree_count = len(CoNLLU) - source_tree_count\n",
    "\n",
    "print(source_tree_count, target_tree_count)\n",
    "\n",
    "PQ_Trees = [trees.conllTree_to_pqTree_unlabeled(conll.to_tree()) for conll in CoNLLU]\n",
    "PQ_Index = [Profile(tree, p=2, q=2) for tree in PQ_Trees]\n",
    "\n",
    "J = set(PQ_Index[0])\n",
    "for pq_set  in PQ_Index[1:]:\n",
    "    J = J.union(pq_set)\n",
    "J = list(J)\n",
    "\n",
    "tensors_source = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[:source_tree_count], desc=\"[convert tensor]\")]\n",
    "tensors_target = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[source_tree_count:], desc=\"[convert tensor]\")]\n",
    "\n",
    "\n",
    "model_path = \"models/model_En-EWT_Ko-Kaist_unlabel_50.pth\"\n",
    "distance_function = w_pq.WeightedPqgramDistance(tensors_source[0].size(), [], [])\n",
    "distance_function.load_state_dict(torch.load(model_path))\n",
    "distance_function.eval()\n",
    "weights = distance_function.weights\n",
    "\n",
    "a = []\n",
    "for _ in range(source_tree_count):\n",
    "    a.append(1/source_tree_count)\n",
    "b = []\n",
    "for _ in range(target_tree_count):\n",
    "    b.append(1/target_tree_count)\n",
    "\n",
    "cost_matrix = torch.zeros((source_tree_count, target_tree_count))\n",
    "\n",
    "tensors_source = torch.stack([t.to(\"cuda:3\") for t in tensors_source])\n",
    "tensors_target = torch.stack([t.to(\"cuda:3\") for t in tensors_target])\n",
    "\n",
    "for i in tqdm(range(source_tree_count), desc=\"[cost matrix]\"):\n",
    "    t_source = tensors_source[i].unsqueeze(0)\n",
    "    cost_matrix[i] = w_pq.weighted_pqgram_distance_batch(weights, tensors_target, t_source.repeat(tensors_target.size(0), 1))\n",
    "\n",
    "print(ot.emd2(a, b, cost_matrix.detach().numpy(), numItermax=1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fr-GSD -- Ja-BCCWJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 14450\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62227c3f7244e3197a1602fd208b38f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaeabae0df6d4cbaa44a00a41e664158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/14450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7486852b08254dddb992ef5e045d1dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[cost matrix]:   0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4892249959879988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamazoe/.pyenv/versions/3.11.7/envs/env_pq/lib/python3.11/site-packages/ot/lp/__init__.py:580: UserWarning: numItermax reached before optimality. Try to increase numItermax.\n",
      "  check_result(result_code)\n"
     ]
    }
   ],
   "source": [
    "CoNLLU_source_PATH = \"corpora/Japanese/Japanese-BCCWJ.conllu\"\n",
    "CoNLLU = random.sample(pyconll.load_from_file(CoNLLU_source_PATH), k=30000)\n",
    "source_tree_count = len(CoNLLU)\n",
    "\n",
    "CoNLLU_target_PATH = \"corpora/French/French-GSD.conllu\"\n",
    "CoNLLU += pyconll.load_from_file(CoNLLU_target_PATH)\n",
    "target_tree_count = len(CoNLLU) - source_tree_count\n",
    "\n",
    "print(source_tree_count, target_tree_count)\n",
    "\n",
    "PQ_Trees = [trees.conllTree_to_pqTree_unlabeled(conll.to_tree()) for conll in CoNLLU]\n",
    "PQ_Index = [Profile(tree, p=2, q=2) for tree in PQ_Trees]\n",
    "\n",
    "J = set(PQ_Index[0])\n",
    "for pq_set  in PQ_Index[1:]:\n",
    "    J = J.union(pq_set)\n",
    "J = list(J)\n",
    "\n",
    "tensors_source = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[:source_tree_count], desc=\"[convert tensor]\")]\n",
    "tensors_target = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[source_tree_count:], desc=\"[convert tensor]\")]\n",
    "\n",
    "\n",
    "model_path = \"models/model_Fr-GSD_Ja-BCCWJ_unlabel_50.pth\"\n",
    "distance_function = w_pq.WeightedPqgramDistance(tensors_source[0].size(), [], [])\n",
    "distance_function.load_state_dict(torch.load(model_path))\n",
    "distance_function.eval()\n",
    "weights = distance_function.weights\n",
    "\n",
    "a = []\n",
    "for _ in range(source_tree_count):\n",
    "    a.append(1/source_tree_count)\n",
    "b = []\n",
    "for _ in range(target_tree_count):\n",
    "    b.append(1/target_tree_count)\n",
    "\n",
    "cost_matrix = torch.zeros((source_tree_count, target_tree_count))\n",
    "\n",
    "tensors_source = torch.stack([t.to(\"cuda:3\") for t in tensors_source])\n",
    "tensors_target = torch.stack([t.to(\"cuda:3\") for t in tensors_target])\n",
    "\n",
    "\n",
    "for i in tqdm(range(source_tree_count), desc=\"[cost matrix]\"):\n",
    "    t_source = tensors_source[i].unsqueeze(0)\n",
    "    cost_matrix[i] = w_pq.weighted_pqgram_distance_batch(weights, tensors_target, t_source.repeat(tensors_target.size(0), 1)).to(\"cpu\")\n",
    "\n",
    "\n",
    "print(ot.emd2(a, b, cost_matrix.detach().numpy(), numItermax=1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fr-GSD -- Korean-kaist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23010 14450\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8dfdcf2c3742a3a4dbe5dbec5196ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/23010 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b2e656970f4013ace9e028cc42ce59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/14450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c83dbbb4ac4f9a9bfdf13b3e2693b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[cost matrix]:   0%|          | 0/23010 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.481494471447322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamazoe/.pyenv/versions/3.11.7/envs/env_pq/lib/python3.11/site-packages/ot/lp/__init__.py:580: UserWarning: numItermax reached before optimality. Try to increase numItermax.\n",
      "  check_result(result_code)\n"
     ]
    }
   ],
   "source": [
    "CoNLLU_source_PATH = \"corpora/Korean/Korean-Kaist.conllu\"\n",
    "CoNLLU = pyconll.load_from_file(CoNLLU_source_PATH)\n",
    "source_tree_count = len(CoNLLU)\n",
    "\n",
    "CoNLLU_target_PATH = \"corpora/French/French-GSD.conllu\"\n",
    "CoNLLU += pyconll.load_from_file(CoNLLU_target_PATH)\n",
    "target_tree_count = len(CoNLLU) - source_tree_count\n",
    "\n",
    "print(source_tree_count, target_tree_count)\n",
    "\n",
    "PQ_Trees = [trees.conllTree_to_pqTree_unlabeled(conll.to_tree()) for conll in CoNLLU]\n",
    "PQ_Index = [Profile(tree, p=2, q=2) for tree in PQ_Trees]\n",
    "\n",
    "J = set(PQ_Index[0])\n",
    "for pq_set  in PQ_Index[1:]:\n",
    "    J = J.union(pq_set)\n",
    "J = list(J)\n",
    "\n",
    "tensors_source = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[:source_tree_count], desc=\"[convert tensor]\")]\n",
    "tensors_target = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[source_tree_count:], desc=\"[convert tensor]\")]\n",
    "\n",
    "\n",
    "model_path = \"models/model_Fr-GSD_Ko-Kaist_unlabel_50.pth\"\n",
    "distance_function = w_pq.WeightedPqgramDistance(tensors_source[0].size(), [], [])\n",
    "distance_function.load_state_dict(torch.load(model_path))\n",
    "distance_function.eval()\n",
    "weights = distance_function.weights\n",
    "\n",
    "a = []\n",
    "for _ in range(source_tree_count):\n",
    "    a.append(1/source_tree_count)\n",
    "b = []\n",
    "for _ in range(target_tree_count):\n",
    "    b.append(1/target_tree_count)\n",
    "\n",
    "cost_matrix = torch.zeros((source_tree_count, target_tree_count))\n",
    "\n",
    "tensors_source = torch.stack([t.to(\"cuda:3\") for t in tensors_source])\n",
    "tensors_target = torch.stack([t.to(\"cuda:3\") for t in tensors_target])\n",
    "\n",
    "\n",
    "for i in tqdm(range(source_tree_count), desc=\"[cost matrix]\"):\n",
    "    t_source = tensors_source[i].unsqueeze(0)\n",
    "    cost_matrix[i] = w_pq.weighted_pqgram_distance_batch(weights, tensors_target, t_source.repeat(tensors_target.size(0), 1)).to(\"cpu\")\n",
    "\n",
    "\n",
    "print(ot.emd2(a, b, cost_matrix.detach().numpy(), numItermax=1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ja-BCCWJ -- Ko-Kaist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23010 30000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2341c3f7831f4bb9b4fa7f509d6d1cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/23010 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83257fb631ef4fd5ade765db767db007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb6a6982d93a44d296177bab0fe54961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[cost matrix]:   0%|          | 0/23010 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6388610794329189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamazoe/.pyenv/versions/3.11.7/envs/env_pq/lib/python3.11/site-packages/ot/lp/__init__.py:580: UserWarning: numItermax reached before optimality. Try to increase numItermax.\n",
      "  check_result(result_code)\n"
     ]
    }
   ],
   "source": [
    "CoNLLU_source_PATH = \"corpora/Korean/Korean-Kaist.conllu\"\n",
    "CoNLLU = pyconll.load_from_file(CoNLLU_source_PATH)\n",
    "source_tree_count = len(CoNLLU)\n",
    "\n",
    "CoNLLU_target_PATH = \"corpora/Japanese/Japanese-BCCWJ.conllu\"\n",
    "CoNLLU += random.sample(pyconll.load_from_file(CoNLLU_target_PATH), k=30000)\n",
    "target_tree_count = len(CoNLLU) - source_tree_count\n",
    "\n",
    "print(source_tree_count, target_tree_count)\n",
    "\n",
    "PQ_Trees = [trees.conllTree_to_pqTree_unlabeled(conll.to_tree()) for conll in CoNLLU]\n",
    "PQ_Index = [Profile(tree, p=2, q=2) for tree in PQ_Trees]\n",
    "\n",
    "J = set(PQ_Index[0])\n",
    "for pq_set  in PQ_Index[1:]:\n",
    "    J = J.union(pq_set)\n",
    "J = list(J)\n",
    "\n",
    "tensors_source = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[:source_tree_count], desc=\"[convert tensor]\")]\n",
    "tensors_target = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[source_tree_count:], desc=\"[convert tensor]\")]\n",
    "\n",
    "\n",
    "model_path = \"models/model_Ja-BCCWJ_Ko-Kaist_unlabel_50.pth\"\n",
    "distance_function = w_pq.WeightedPqgramDistance(tensors_source[0].size(), [], [])\n",
    "distance_function.load_state_dict(torch.load(model_path))\n",
    "distance_function.eval()\n",
    "weights = distance_function.weights\n",
    "\n",
    "a = []\n",
    "for _ in range(source_tree_count):\n",
    "    a.append(1/source_tree_count)\n",
    "b = []\n",
    "for _ in range(target_tree_count):\n",
    "    b.append(1/target_tree_count)\n",
    "\n",
    "cost_matrix = torch.zeros((source_tree_count, target_tree_count))\n",
    "\n",
    "tensors_source = torch.stack([t.to(\"cuda:3\") for t in tensors_source])\n",
    "tensors_target = torch.stack([t.to(\"cuda:3\") for t in tensors_target])\n",
    "\n",
    "\n",
    "for i in tqdm(range(source_tree_count), desc=\"[cost matrix]\"):\n",
    "    t_source = tensors_source[i].unsqueeze(0)\n",
    "    cost_matrix[i] = w_pq.weighted_pqgram_distance_batch(weights, tensors_target, t_source.repeat(tensors_target.size(0), 1)).to(\"cpu\")\n",
    "\n",
    "\n",
    "print(ot.emd2(a, b, cost_matrix.detach().numpy(), numItermax=1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3997 30000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b2855d873441bbb36c0a332aee72cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/3997 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bfac250f15c41209bfac93ed64ab1f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a66bd5d3c231473e9b286a23538409fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[cost matrix]:   0%|          | 0/3997 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9918164736164332\n"
     ]
    }
   ],
   "source": [
    "CoNLLU_source_PATH = \"corpora/Chinese/Chinese-GSD.conllu\"\n",
    "CoNLLU = pyconll.load_from_file(CoNLLU_source_PATH)\n",
    "source_tree_count = len(CoNLLU)\n",
    "\n",
    "CoNLLU_target_PATH = \"corpora/Japanese/Japanese-BCCWJ.conllu\"\n",
    "CoNLLU += random.sample(pyconll.load_from_file(CoNLLU_target_PATH), k=30000)\n",
    "target_tree_count = len(CoNLLU) - source_tree_count\n",
    "\n",
    "print(source_tree_count, target_tree_count)\n",
    "\n",
    "PQ_Trees = [trees.conllTree_to_pqTree_unlabeled(conll.to_tree()) for conll in CoNLLU]\n",
    "PQ_Index = [Profile(tree, p=2, q=2) for tree in PQ_Trees]\n",
    "\n",
    "J = set(PQ_Index[0])\n",
    "for pq_set  in PQ_Index[1:]:\n",
    "    J = J.union(pq_set)\n",
    "J = list(J)\n",
    "\n",
    "tensors_source = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[:source_tree_count], desc=\"[convert tensor]\")]\n",
    "tensors_target = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[source_tree_count:], desc=\"[convert tensor]\")]\n",
    "\n",
    "\n",
    "model_path = \"models/model_Chinese-GSD_Japanese-BCCWJ_unlabel_50.pth\"\n",
    "distance_function = w_pq.WeightedPqgramDistance(tensors_source[0].size(), [], [])\n",
    "distance_function.load_state_dict(torch.load(model_path))\n",
    "distance_function.eval()\n",
    "weights = distance_function.weights\n",
    "\n",
    "a = []\n",
    "for _ in range(source_tree_count):\n",
    "    a.append(1/source_tree_count)\n",
    "b = []\n",
    "for _ in range(target_tree_count):\n",
    "    b.append(1/target_tree_count)\n",
    "\n",
    "cost_matrix = torch.zeros((source_tree_count, target_tree_count))\n",
    "\n",
    "tensors_source = torch.stack([t.to(\"cuda:3\") for t in tensors_source])\n",
    "tensors_target = torch.stack([t.to(\"cuda:3\") for t in tensors_target])\n",
    "\n",
    "\n",
    "for i in tqdm(range(source_tree_count), desc=\"[cost matrix]\"):\n",
    "    t_source = tensors_source[i].unsqueeze(0)\n",
    "    cost_matrix[i] = w_pq.weighted_pqgram_distance_batch(weights, tensors_target, t_source.repeat(tensors_target.size(0), 1)).to(\"cpu\")\n",
    "\n",
    "\n",
    "print(ot.emd2(a, b, cost_matrix.detach().numpy(), numItermax=1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3997 16621\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16ca5d01fda48ccbf0d5e70c1586562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/3997 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7756b6f7a3fa403fabb42361458b28d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/16621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68fda530191044aab679d2c3d224421d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[cost matrix]:   0%|          | 0/3997 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.022910527215509\n"
     ]
    }
   ],
   "source": [
    "CoNLLU_source_PATH = \"corpora/Chinese/Chinese-GSD.conllu\"\n",
    "CoNLLU = pyconll.load_from_file(CoNLLU_source_PATH)\n",
    "source_tree_count = len(CoNLLU)\n",
    "\n",
    "CoNLLU_target_PATH = \"corpora/English/English-EWT.conllu\"\n",
    "CoNLLU += pyconll.load_from_file(CoNLLU_target_PATH)\n",
    "target_tree_count = len(CoNLLU) - source_tree_count\n",
    "\n",
    "print(source_tree_count, target_tree_count)\n",
    "\n",
    "PQ_Trees = [trees.conllTree_to_pqTree_unlabeled(conll.to_tree()) for conll in CoNLLU]\n",
    "PQ_Index = [Profile(tree, p=2, q=2) for tree in PQ_Trees]\n",
    "\n",
    "J = set(PQ_Index[0])\n",
    "for pq_set  in PQ_Index[1:]:\n",
    "    J = J.union(pq_set)\n",
    "J = list(J)\n",
    "\n",
    "tensors_source = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[:source_tree_count], desc=\"[convert tensor]\")]\n",
    "tensors_target = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[source_tree_count:], desc=\"[convert tensor]\")]\n",
    "\n",
    "\n",
    "model_path = \"models/model_Chinese-GSD_English-EWT_unlabel_50.pth\"\n",
    "distance_function = w_pq.WeightedPqgramDistance(tensors_source[0].size(), [], [])\n",
    "distance_function.load_state_dict(torch.load(model_path))\n",
    "distance_function.eval()\n",
    "weights = distance_function.weights\n",
    "\n",
    "a = []\n",
    "for _ in range(source_tree_count):\n",
    "    a.append(1/source_tree_count)\n",
    "b = []\n",
    "for _ in range(target_tree_count):\n",
    "    b.append(1/target_tree_count)\n",
    "\n",
    "cost_matrix = torch.zeros((source_tree_count, target_tree_count))\n",
    "\n",
    "tensors_source = torch.stack([t.to(\"cuda:3\") for t in tensors_source])\n",
    "tensors_target = torch.stack([t.to(\"cuda:3\") for t in tensors_target])\n",
    "\n",
    "\n",
    "for i in tqdm(range(source_tree_count), desc=\"[cost matrix]\"):\n",
    "    t_source = tensors_source[i].unsqueeze(0)\n",
    "    cost_matrix[i] = w_pq.weighted_pqgram_distance_batch(weights, tensors_target, t_source.repeat(tensors_target.size(0), 1)).to(\"cpu\")\n",
    "\n",
    "\n",
    "print(ot.emd2(a, b, cost_matrix.detach().numpy(), numItermax=1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3997 14450\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16596fe4c4f94d78b5446bf5fd9f428b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/3997 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34527bf1a2974d84a82f479ccee4ced1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/14450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41bc6e16a03344c088d24ef3f89d43c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[cost matrix]:   0%|          | 0/3997 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5812372912845252\n"
     ]
    }
   ],
   "source": [
    "CoNLLU_source_PATH = \"corpora/Chinese/Chinese-GSD.conllu\"\n",
    "CoNLLU = pyconll.load_from_file(CoNLLU_source_PATH)\n",
    "source_tree_count = len(CoNLLU)\n",
    "\n",
    "CoNLLU_target_PATH = \"corpora/French/French-GSD.conllu\"\n",
    "CoNLLU += pyconll.load_from_file(CoNLLU_target_PATH)\n",
    "target_tree_count = len(CoNLLU) - source_tree_count\n",
    "\n",
    "print(source_tree_count, target_tree_count)\n",
    "\n",
    "PQ_Trees = [trees.conllTree_to_pqTree_unlabeled(conll.to_tree()) for conll in CoNLLU]\n",
    "PQ_Index = [Profile(tree, p=2, q=2) for tree in PQ_Trees]\n",
    "\n",
    "J = set(PQ_Index[0])\n",
    "for pq_set  in PQ_Index[1:]:\n",
    "    J = J.union(pq_set)\n",
    "J = list(J)\n",
    "\n",
    "tensors_source = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[:source_tree_count], desc=\"[convert tensor]\")]\n",
    "tensors_target = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[source_tree_count:], desc=\"[convert tensor]\")]\n",
    "\n",
    "\n",
    "model_path = \"models/model_Chinese-GSD_French-GSD_unlabel_50.pth\"\n",
    "distance_function = w_pq.WeightedPqgramDistance(tensors_source[0].size(), [], [])\n",
    "distance_function.load_state_dict(torch.load(model_path))\n",
    "distance_function.eval()\n",
    "weights = distance_function.weights\n",
    "\n",
    "a = []\n",
    "for _ in range(source_tree_count):\n",
    "    a.append(1/source_tree_count)\n",
    "b = []\n",
    "for _ in range(target_tree_count):\n",
    "    b.append(1/target_tree_count)\n",
    "\n",
    "cost_matrix = torch.zeros((source_tree_count, target_tree_count))\n",
    "\n",
    "tensors_source = torch.stack([t.to(\"cuda:3\") for t in tensors_source])\n",
    "tensors_target = torch.stack([t.to(\"cuda:3\") for t in tensors_target])\n",
    "\n",
    "\n",
    "for i in tqdm(range(source_tree_count), desc=\"[cost matrix]\"):\n",
    "    t_source = tensors_source[i].unsqueeze(0)\n",
    "    cost_matrix[i] = w_pq.weighted_pqgram_distance_batch(weights, tensors_target, t_source.repeat(tensors_target.size(0), 1)).to(\"cpu\")\n",
    "\n",
    "\n",
    "print(ot.emd2(a, b, cost_matrix.detach().numpy(), numItermax=1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3997 23010\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f24500114cb4d1bb2e50f219f380a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/3997 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a7a706b45af4bc884614effed201b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/23010 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd9d75aecaa4766ae34b7b8dad603c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[cost matrix]:   0%|          | 0/3997 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.241156247193615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamazoe/.pyenv/versions/3.11.7/envs/env_pq/lib/python3.11/site-packages/ot/lp/__init__.py:580: UserWarning: numItermax reached before optimality. Try to increase numItermax.\n",
      "  check_result(result_code)\n"
     ]
    }
   ],
   "source": [
    "CoNLLU_source_PATH = \"corpora/Chinese/Chinese-GSD.conllu\"\n",
    "CoNLLU = pyconll.load_from_file(CoNLLU_source_PATH)\n",
    "source_tree_count = len(CoNLLU)\n",
    "\n",
    "CoNLLU_target_PATH = \"corpora/Korean/Korean-Kaist.conllu\"\n",
    "CoNLLU += pyconll.load_from_file(CoNLLU_target_PATH)\n",
    "target_tree_count = len(CoNLLU) - source_tree_count\n",
    "\n",
    "print(source_tree_count, target_tree_count)\n",
    "\n",
    "PQ_Trees = [trees.conllTree_to_pqTree_unlabeled(conll.to_tree()) for conll in CoNLLU]\n",
    "PQ_Index = [Profile(tree, p=2, q=2) for tree in PQ_Trees]\n",
    "\n",
    "J = set(PQ_Index[0])\n",
    "for pq_set  in PQ_Index[1:]:\n",
    "    J = J.union(pq_set)\n",
    "J = list(J)\n",
    "\n",
    "tensors_source = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[:source_tree_count], desc=\"[convert tensor]\")]\n",
    "tensors_target = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[source_tree_count:], desc=\"[convert tensor]\")]\n",
    "\n",
    "\n",
    "model_path = \"models/model_Chinese-GSD_Korean-Kaist_unlabel_50.pth\"\n",
    "distance_function = w_pq.WeightedPqgramDistance(tensors_source[0].size(), [], [])\n",
    "distance_function.load_state_dict(torch.load(model_path))\n",
    "distance_function.eval()\n",
    "weights = distance_function.weights\n",
    "\n",
    "a = []\n",
    "for _ in range(source_tree_count):\n",
    "    a.append(1/source_tree_count)\n",
    "b = []\n",
    "for _ in range(target_tree_count):\n",
    "    b.append(1/target_tree_count)\n",
    "\n",
    "cost_matrix = torch.zeros((source_tree_count, target_tree_count))\n",
    "\n",
    "tensors_source = torch.stack([t.to(\"cuda:3\") for t in tensors_source])\n",
    "tensors_target = torch.stack([t.to(\"cuda:3\") for t in tensors_target])\n",
    "\n",
    "\n",
    "for i in tqdm(range(source_tree_count), desc=\"[cost matrix]\"):\n",
    "    t_source = tensors_source[i].unsqueeze(0)\n",
    "    cost_matrix[i] = w_pq.weighted_pqgram_distance_batch(weights, tensors_target, t_source.repeat(tensors_target.size(0), 1)).to(\"cpu\")\n",
    "\n",
    "\n",
    "print(ot.emd2(a, b, cost_matrix.detach().numpy(), numItermax=1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## デンドログラムの作成例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Dendrogram (weighted, unlabel)')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat = np.array([\n",
    "    [0.0, 2.9210620399488905, 3.909186519127199, 2.889577513517188, 4.022910527215509],\n",
    "    [2.9210620399488905, 0.0, 1.6574226261167868, 0.6388610794329189, 1.9918164736164332],\n",
    "    [3.909186519127199, 1.6574226261167868, 0.0, 6.481494471447322, 1.5812372912845252],\n",
    "    [2.889577513517188, 0.6388610794329189, 6.481494471447322, 0.0, 10.241156247193615],\n",
    "    [4.022910527215509, 1.9918164736164332, 1.5812372912845252, 10.241156247193615, 0.0]\n",
    "])\n",
    "\n",
    "condensed_distance = distance.squareform(mat)\n",
    "\n",
    "linkage_matrix = linkage(condensed_distance, method=\"ward\")\n",
    "\n",
    "plt.figure()\n",
    "dend = dendrogram(linkage_matrix, labels=[\"English\", \"Japanese\", \"French\", \"Korean\", \"Chinese\"])\n",
    "plt.yticks([])\n",
    "plt.title(\"Dendrogram (weighted, unlabel)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ノードラベルを品詞にしたとき"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14450 8100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b30c9b66074b7da22b1d34530db091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/14450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f3cfac9883244fb84c0f7ab488e327c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/8100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "766bf0e538c044a2b27ec77a967e345f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[cost matrix]:   0%|          | 0/14450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 23.65 GiB of which 188.25 MiB is free. Process 161512 has 6.32 GiB memory in use. Including non-PyTorch memory, this process has 17.13 GiB memory in use. Of the allocated memory 16.60 GiB is allocated by PyTorch, and 98.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(source_tree_count), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[cost matrix]\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     43\u001b[0m     t_source \u001b[38;5;241m=\u001b[39m tensors_source[i]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m     cost_matrix[i] \u001b[38;5;241m=\u001b[39m \u001b[43mw_pq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweighted_pqgram_distance_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_source\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors_target\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(ot\u001b[38;5;241m.\u001b[39memd2(a, b, cost_matrix\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), numItermax\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000000\u001b[39m))\n",
      "File \u001b[0;32m/misc/home/yamazoe/zoe/scripts/w_pq_batch.py:35\u001b[0m, in \u001b[0;36mweighted_pqgram_distance_batch\u001b[0;34m(weights, batch1, batch2)\u001b[0m\n\u001b[1;32m     33\u001b[0m device \u001b[38;5;241m=\u001b[39m batch1\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m     34\u001b[0m min12 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mminimum(batch1, batch2)\n\u001b[0;32m---> 35\u001b[0m diff \u001b[38;5;241m=\u001b[39m \u001b[43mbatch1\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mbatch2\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmin12\u001b[49m\n\u001b[1;32m     36\u001b[0m aw \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39msoftplus(weights\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (diff\u001b[38;5;241m*\u001b[39maw)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 23.65 GiB of which 188.25 MiB is free. Process 161512 has 6.32 GiB memory in use. Including non-PyTorch memory, this process has 17.13 GiB memory in use. Of the allocated memory 16.60 GiB is allocated by PyTorch, and 98.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "CoNLLU_source_PATH = \"corpora/French/French-GSD.conllu\"\n",
    "CoNLLU = pyconll.load_from_file(CoNLLU_source_PATH)\n",
    "source_tree_count = len(CoNLLU)\n",
    "\n",
    "CoNLLU_target_PATH = \"corpora/Japanese/Japanese-GSDLUW.conllu\"\n",
    "CoNLLU += pyconll.load_from_file(CoNLLU_target_PATH)\n",
    "target_tree_count = len(CoNLLU) - source_tree_count\n",
    "\n",
    "print(source_tree_count, target_tree_count)\n",
    "\n",
    "PQ_Trees = [trees.conllTree_to_pqTree_upos(conll.to_tree()) for conll in CoNLLU]\n",
    "PQ_Index = [Profile(tree, p=2, q=2) for tree in PQ_Trees]\n",
    "\n",
    "J = set(PQ_Index[0])\n",
    "for pq_set  in PQ_Index[1:]:\n",
    "    J = J.union(pq_set)\n",
    "J = list(J)\n",
    "\n",
    "tensors_source = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[:source_tree_count], desc=\"[convert tensor]\")]\n",
    "tensors_target = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[source_tree_count:], desc=\"[convert tensor]\")]\n",
    "\n",
    "\n",
    "model_path = \"models/model_French-GSD_Japanese-GSDLUW_upos_50.pth\"\n",
    "distance_function = w_pq.WeightedPqgramDistance(tensors_source[0].size(), [], [])\n",
    "distance_function.load_state_dict(torch.load(model_path))\n",
    "distance_function.eval()\n",
    "weights = distance_function.weights\n",
    "\n",
    "a = []\n",
    "for _ in range(source_tree_count):\n",
    "    a.append(1/source_tree_count)\n",
    "b = []\n",
    "for _ in range(target_tree_count):\n",
    "    b.append(1/target_tree_count)\n",
    "\n",
    "cost_matrix = torch.zeros((source_tree_count, target_tree_count))\n",
    "\n",
    "tensors_source = torch.stack([t.to(\"cuda:0\") for t in tensors_source])\n",
    "tensors_target = torch.stack([t.to(\"cuda:0\") for t in tensors_target])\n",
    "\n",
    "\n",
    "for i in tqdm(range(source_tree_count), desc=\"[cost matrix]\"):\n",
    "    t_source = tensors_source[i].unsqueeze(0)\n",
    "    cost_matrix[i] = w_pq.weighted_pqgram_distance_batch(weights, tensors_target, t_source.repeat(tensors_target.size(0), 1)).to(\"cpu\")\n",
    "\n",
    "\n",
    "print(ot.emd2(a, b, cost_matrix.detach().numpy(), numItermax=1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習しないでやると"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14450 3997\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb170766d5f40d1bcafe7e9bb0f6534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/14450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a0198a2d8a43118ea7b23c8e5b8b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[convert tensor]:   0%|          | 0/3997 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0f43937438c4e708513582465d78a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[cost matrix]:   0%|          | 0/14450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.305707212931308\n"
     ]
    }
   ],
   "source": [
    "CoNLLU_source_PATH = \"corpora/French/French-GSD.conllu\"\n",
    "CoNLLU = pyconll.load_from_file(CoNLLU_source_PATH)\n",
    "source_tree_count = len(CoNLLU)\n",
    "\n",
    "CoNLLU_target_PATH = \"corpora/Chinese/Chinese-GSD.conllu\"\n",
    "CoNLLU += pyconll.load_from_file(CoNLLU_target_PATH)\n",
    "target_tree_count = len(CoNLLU) - source_tree_count\n",
    "\n",
    "print(source_tree_count, target_tree_count)\n",
    "\n",
    "PQ_Trees = [trees.conllTree_to_pqTree_unlabeled(conll.to_tree()) for conll in CoNLLU]\n",
    "PQ_Index = [Profile(tree, p=2, q=2) for tree in PQ_Trees]\n",
    "\n",
    "J = set(PQ_Index[0])\n",
    "for pq_set  in PQ_Index[1:]:\n",
    "    J = J.union(pq_set)\n",
    "J = list(J)\n",
    "\n",
    "tensors_source = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[:source_tree_count], desc=\"[convert tensor]\")]\n",
    "tensors_target = [pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in tqdm(PQ_Index[source_tree_count:], desc=\"[convert tensor]\")]\n",
    "\n",
    "weights = torch.ones(len(J))\n",
    "\n",
    "a = []\n",
    "for _ in range(source_tree_count):\n",
    "    a.append(1/source_tree_count)\n",
    "b = []\n",
    "for _ in range(target_tree_count):\n",
    "    b.append(1/target_tree_count)\n",
    "\n",
    "cost_matrix = torch.zeros((source_tree_count, target_tree_count))\n",
    "\n",
    "tensors_source = torch.stack([t.to(\"cuda:3\") for t in tensors_source])\n",
    "tensors_target = torch.stack([t.to(\"cuda:3\") for t in tensors_target])\n",
    "\n",
    "for i in tqdm(range(source_tree_count), desc=\"[cost matrix]\"):\n",
    "    t_source = tensors_source[i].unsqueeze(0)\n",
    "    cost_matrix[i] = w_pq.weighted_pqgram_distance_batch(weights, tensors_target, t_source.repeat(tensors_target.size(0), 1))\n",
    "\n",
    "print(ot.emd2(a, b, cost_matrix.detach().numpy(), numItermax=1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Dendrogram (pure-$pq$gram, unlabel)')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat = np.array([\n",
    "    [0.0,   13.921808713761822, 24.462756607012043,\t16.37367393637651,\t24.727866582687017],\n",
    "    [13.921808713761822,\t0.0,\t13.283233099995035,\t20.98275578765745,\t15.733250120095386],\n",
    "    [24.462756607012043,\t13.283233099995035,\t0.0,\t27.790417556951798,\t6.305707212931308],\n",
    "    [16.37367393637651,\t20.98275578765745,\t27.790417556951798,\t0.0,\t30.96447059833724],\n",
    "    [24.727866582687017,\t15.733250120095386,\t6.305707212931308,\t30.96447059833724,\t0.0]\n",
    "])\n",
    "\n",
    "condensed_distance = distance.squareform(mat)\n",
    "\n",
    "linkage_matrix = linkage(condensed_distance, method=\"ward\")\n",
    "\n",
    "plt.figure()\n",
    "dend = dendrogram(linkage_matrix, labels=[\"English\", \"Japanese\", \"French\", \"Korean\", \"Chinese\"])\n",
    "plt.yticks([])\n",
    "plt.title(r\"Dendrogram (pure-$pq$gram, unlabel)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TED ならどうなる？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "906c8b8dc8c34804bf55c70545e636e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[cost matrix]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.339999746531248\n"
     ]
    }
   ],
   "source": [
    "CoNLLU_source_PATH = \"corpora/French/French-GSD.conllu\"\n",
    "CoNLLU_src = random.sample(pyconll.load_from_file(CoNLLU_source_PATH), k=100)\n",
    "source_tree_count = len(CoNLLU_src)\n",
    "\n",
    "CoNLLU_target_PATH = \"corpora/Chinese/Chinese-GSD.conllu\"\n",
    "CoNLLU_tar = random.sample(pyconll.load_from_file(CoNLLU_target_PATH), k=100)\n",
    "target_tree_count = len(CoNLLU_tar)\n",
    "\n",
    "zss_trees_src = [trees.conllTree_to_zssNode_unlabel(conll.to_tree()) for conll in CoNLLU_src]\n",
    "zss_trees_tar = [trees.conllTree_to_zssNode_unlabel(conll.to_tree()) for conll in CoNLLU_tar]\n",
    "\n",
    "a = []\n",
    "for _ in range(source_tree_count):\n",
    "    a.append(1/source_tree_count)\n",
    "b = []\n",
    "for _ in range(target_tree_count):\n",
    "    b.append(1/target_tree_count)\n",
    "\n",
    "cost_matrix = torch.zeros((source_tree_count, target_tree_count))\n",
    "\n",
    "for i, src in tqdm(enumerate(zss_trees_src), desc=\"[cost matrix]\"):\n",
    "    for j, tar in enumerate(zss_trees_tar):\n",
    "        cost_matrix[i,j] = zss.simple_distance(src, tar)\n",
    "        \n",
    "\n",
    "print(ot.emd2(a, b, cost_matrix.detach().numpy(), numItermax=1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
