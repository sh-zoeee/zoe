{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "import time\n",
    "from pqgrams.tree import Node\n",
    "from pqgrams.PQGram import Profile\n",
    "import zss\n",
    "import scripts.pq_gram, scripts.dist, scripts.visualize, scripts.w_pq\n",
    "from collections import Counter\n",
    "import pyconll\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from xml.etree import ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.5, 1. ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ndarray(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# np.ndarrayとtorch.Tensorによる計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3327, -0.3698]) [ 0.3326949 -0.3697978]\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randn(2)\n",
    "vector = tensor.detach().numpy()\n",
    "\n",
    "print(tensor, vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(tensor), type(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softplus(x:np.ndarray|torch.Tensor):\n",
    "  if (type(x)==np.ndarray):\n",
    "    return np.log(1+np.exp(x))\n",
    "  elif (type(x)==torch.Tensor):\n",
    "    return torch.log(torch.ones(x.size()[0], dtype=torch.float32).to(x.device)+torch.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87326705, 0.52524555], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softplus(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_vec(dim: int):\n",
    "  tensor = torch.randn(dim)\n",
    "  vector = tensor.detach().numpy()\n",
    "  return tensor, vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors, vectors = [], []\n",
    "for _ in range(1000):\n",
    "  tensor, vector = random_vec(2)\n",
    "  tensors.append(tensor)\n",
    "  vectors.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00832819938659668\n",
      "\n",
      "0.07359433174133301\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for i in range(1000):\n",
    "  softplus(vectors[i])\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "print()\n",
    "start = time.time()\n",
    "for i in range(1000):\n",
    "  softplus(tensors[i])\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 木構造のサンプル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 木構造1\n",
    "\"\"\"\n",
    "  a\n",
    " /|\\\n",
    "a b c\n",
    "|\\\n",
    "e b \n",
    "\"\"\"\n",
    "root1 = Node(\"a\")\n",
    "root1.addkid(Node(\"a\"))\n",
    "root1.addkid(Node(\"b\"))\n",
    "root1.addkid(Node(\"c\"))\n",
    "root1.children[0].addkid(Node(\"e\"))\n",
    "root1.children[0].addkid(Node(\"b\"))\n",
    "\n",
    "\n",
    "# 木構造2\n",
    "\"\"\"\n",
    "  a\n",
    " /|\\\n",
    "a b d\n",
    "|\\\n",
    "e b\n",
    "\"\"\"\n",
    "root2 = Node(\"a\")\n",
    "root2.addkid(Node(\"a\"))\n",
    "root2.addkid(Node(\"b\"))\n",
    "root2.addkid(Node(\"d\"))\n",
    "root2.children[0].addkid(Node(\"e\"))\n",
    "root2.children[0].addkid(Node(\"b\"))\n",
    "\n",
    "\n",
    "# PQ-Gram プロファイルの作成\n",
    "p1 = Profile(root1, p=2, q=3)\n",
    "p2 = Profile(root2, p=2, q=3)\n",
    "\n",
    "\n",
    "J = [pqgram for pqgram in p1]\n",
    "for pqgram in p2:\n",
    "   if pqgram not in J:\n",
    "      J.append(pqgram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorによる距離計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n"
     ]
    }
   ],
   "source": [
    "tensor1 = scripts.pq_gram.pqgram_to_tensor(p1, J).to(device)\n",
    "tensor2 = scripts.pq_gram.pqgram_to_tensor(p2, J).to(device)\n",
    "\n",
    "\n",
    "print(scripts.dist.pqgram_distance_tensor(tensor1, tensor2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## np.ndarrayによる距離計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n"
     ]
    }
   ],
   "source": [
    "dimension = len(J)\n",
    "\n",
    "v1 = np.zeros(dimension, dtype=int)\n",
    "v2 = np.zeros(dimension, dtype=int)\n",
    "\n",
    "for pqgram in p1:\n",
    "   if pqgram in J:\n",
    "      for i, subtree in enumerate(J):\n",
    "         if pqgram == subtree:\n",
    "            v1[i] += 1\n",
    "\n",
    "for pqgram in p2:\n",
    "   if pqgram in J:\n",
    "      for i, subtree in enumerate(J):\n",
    "         if pqgram == subtree:\n",
    "            v2[i] += 1\n",
    "\n",
    "tensor1 = torch.from_numpy(v1.astype(np.float32)).to(device)\n",
    "tensor2 = torch.from_numpy(v2.astype(np.float32)).to(device)\n",
    "\n",
    "tensor_min = torch.minimum(tensor1, tensor2)\n",
    "\n",
    "min12 = np.minimum(v1, v2)\n",
    "\n",
    "tensor_diff = tensor1 + tensor2 - 2*tensor_min\n",
    "\n",
    "\n",
    "print(((torch.ones(dimension, dtype=torch.float32).to(device=device)@tensor_diff)).to(\"cpu\").detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('a', 'b', '*', '*', '*'): 2,\n",
       "         ('*', 'a', '*', '*', 'a'): 1,\n",
       "         ('*', 'a', '*', 'a', 'b'): 1,\n",
       "         ('*', 'a', 'a', 'b', 'c'): 1,\n",
       "         ('*', 'a', 'b', 'c', '*'): 1,\n",
       "         ('*', 'a', 'c', '*', '*'): 1,\n",
       "         ('a', 'a', '*', '*', 'e'): 1,\n",
       "         ('a', 'a', '*', 'e', 'b'): 1,\n",
       "         ('a', 'a', 'b', '*', '*'): 1,\n",
       "         ('a', 'a', 'e', 'b', '*'): 1,\n",
       "         ('a', 'c', '*', '*', '*'): 1,\n",
       "         ('a', 'e', '*', '*', '*'): 1})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n"
     ]
    }
   ],
   "source": [
    "def pqgram_to_tensor(pqgrams: Profile, J: list) -> torch.Tensor:\n",
    "    dim = len(J)\n",
    "    vec = torch.zeros(dim, dtype=torch.float32)\n",
    "    pqgrams_set = list(set(pqgrams))\n",
    "    counts = Counter(pqgrams)\n",
    "    for pqgram in pqgrams_set:\n",
    "      count = counts[pqgram]\n",
    "      idx = J.index(pqgram)\n",
    "      vec[idx] = count\n",
    "    return vec\n",
    "\n",
    "tensor1_ = pqgram_to_tensor(p1, J)\n",
    "tensor2_ = pqgram_to_tensor(p2, J)\n",
    "print(scripts.dist.pqgram_distance_tensor(tensor1_, tensor2_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scripts.pq_gram\n",
    "import scripts.trees\n",
    "\n",
    "\n",
    "def preprocessing(CORPUS_FILE: list, type_of_labels: list):\n",
    "    \n",
    "    CORPUS_LIST = []\n",
    "    for corpus in CORPUS_FILE:\n",
    "        CORPUS_LIST.append(corpus.split(\".\")[0].split(\"/\")[-1])\n",
    "\n",
    "    CORPUS_i_LENGTH = []\n",
    "\n",
    "    CoNLL = []\n",
    "    labels = []\n",
    "    for i in range(len(CORPUS_FILE)):\n",
    "        tmp_conll = pyconll.load_from_file(CORPUS_FILE[i])\n",
    "        CoNLL += tmp_conll\n",
    "        for _ in range(len(tmp_conll)):\n",
    "            labels.append(type_of_labels[i])\n",
    "        if i != 0:\n",
    "            CORPUS_i_LENGTH.append(len(tmp_conll)+CORPUS_i_LENGTH[i-1])\n",
    "        else:\n",
    "            CORPUS_i_LENGTH.append(len(tmp_conll))\n",
    "    \n",
    "    num_trees = CORPUS_i_LENGTH[-1]\n",
    "    pqtrees = [scripts.trees.conllTree_to_pqTree_upos(conll.to_tree()) for conll in CoNLL]\n",
    "    \n",
    "    pqIndex = [Profile(tree, p=2, q=2) for tree in pqtrees]\n",
    "\n",
    "    J = set(pqIndex[0])\n",
    "    for pq_set in pqIndex[1:]:\n",
    "        J = J.union(pq_set)\n",
    "    J = list(J)\n",
    "\n",
    "    tensors = [scripts.pq_gram.pqgram_to_tensor(pqgram, J) for pqgram in pqIndex]\n",
    "    \n",
    "    indexes = torch.Tensor(range(num_trees))\n",
    "\n",
    "    # 訓練データとテストデータに分割\n",
    "    train_tensors, test_tensors, train_labels, test_labels, train_indexes, test_indexes = train_test_split(tensors, labels, indexes, test_size=0.4, random_state=42)\n",
    "    valid_tensors, test_tensors, valid_labels, test_labels, valid_indexes, test_indexes = train_test_split(tensors, labels, indexes, test_size=0.5, random_state=42)\n",
    "\n",
    "    # データの保存\n",
    "    torch.save(train_tensors, \"data/train_tensors_ja_en_pud.pt\")\n",
    "    torch.save(valid_tensors, \"data/valid_tensors_ja_en_pud.pt\")\n",
    "    torch.save(test_tensors, \"data/test_tensors_ja_en_pud.pt\")\n",
    "\n",
    "    torch.save(train_labels, \"data/train_labels_ja_en_pud.pt\")\n",
    "    torch.save(valid_labels, \"data/valid_labels_ja_en_pud.pt\")\n",
    "    torch.save(test_labels, \"data/test_labels_ja_en_pud.pt\")\n",
    "\n",
    "    torch.save(train_indexes, \"data/train_indexes_ja_en_pud.pt\")\n",
    "    torch.save(valid_indexes, \"data/valid_indexes_ja_en_pud.pt\")\n",
    "    torch.save(test_indexes, \"data/test_indexes_ja_en_pud.pt\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "preprocessing(\n",
    "  [\"PUD/Japanese-PUDLUW.conllu\", \n",
    "    \"PUD/English-PUD.conllu\"],\n",
    "    [\"ja\", \"en\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4504,  1.4049])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6797, -1.4112])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.1823)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts import w_pq\n",
    "dim = tensors[0].size()[0]\n",
    "ones = torch.ones(dim, dtype=torch.float32)\n",
    "w_pq.weighted_pqgram_distance(ones, tensors[0], tensors[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4504,  1.4049]) tensor([ 0.6797, -1.4112])\n",
      "[-0.4504161  1.4048688] [ 0.6796851 -1.4111773]\n"
     ]
    }
   ],
   "source": [
    "array1 = tensors[0].detach().numpy()\n",
    "array2 = tensors[1].detach().numpy()\n",
    "print(tensors[0], tensors[1])\n",
    "print(array1, array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.182324248698053"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min12 = np.minimum(array1, array2)\n",
    "diff = array1+array2-2*min12\n",
    "\n",
    "def softplus_np(x):\n",
    "  return np.log(1+np.exp(x))\n",
    "\n",
    "aw = softplus_np(np.ones(dim))\n",
    "\n",
    "aw @ diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_pqgram_distance(weights, tensor1: torch.Tensor, tensor2: torch.Tensor):\n",
    "    device = tensor1.device\n",
    "    min12 = torch.minimum(tensor1, tensor2).to(device)\n",
    "    diff = tensor1+tensor2-2*min12\n",
    "    aw = scripts.func.softplus(weights).to(device)\n",
    "    return torch.dot(diff, aw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedPqgramDistance(nn.Module):\n",
    "  \n",
    "  def __init__(self, dimension):\n",
    "    super(WeightedPqgramDistance, self).__init__()\n",
    "    self.weights = nn.Parameter(torch.ones(dimension))\n",
    "  \n",
    "  def forward(self, tensor1, tensor2):\n",
    "    dist = weighted_pqgram_distance(self.weights, tensor1, tensor2)\n",
    "    return dist\n",
    "  \n",
    "\n",
    "class MetricLearingLoss(nn.Module):\n",
    "  def __init__(self, margin1, margin2, beta):\n",
    "    super(MetricLearingLoss, self).__init__()\n",
    "    self.margin1 = margin1\n",
    "    self.margin2 = margin2\n",
    "    self.beta = beta\n",
    "  \n",
    "  def forward(self, dist_func, positive_pairs, negative_pairs):\n",
    "    loss = 0.0\n",
    "\n",
    "    for (tensor1, tensor2) in positive_pairs:\n",
    "      dist = dist_func(tensor1, tensor2)\n",
    "      if dist > self.margin1:\n",
    "        loss += dist - self.margin1\n",
    "    \n",
    "    for (tensor1, tensor2) in negative_pairs:\n",
    "      dist = dist_func(tensor1, tensor2)\n",
    "      if dist < self.margin2:\n",
    "        loss += self.margin2 - dist\n",
    "    \n",
    "    reg_term = torch.norm(dist_func.weights)**2\n",
    "    loss += self.beta * reg_term\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m現在のセルまたは前のセルでコードを実行中に、カーネル (Kernel) がクラッシュしました。\n",
      "\u001b[1;31mエラーの原因を特定するには、セル内のコードを確認してください。\n",
      "\u001b[1;31m詳細については<a href='https://aka.ms/vscodeJupyterKernelCrash'>こちら</a>をクリックします。\n",
      "\u001b[1;31m詳細については、Jupyter <a href='command:jupyter.viewOutput'>ログ</a> を参照してください。"
     ]
    }
   ],
   "source": [
    "def distance_matrix(tensors: list, weights):\n",
    "  num_tensor = len(tensors)\n",
    "  dist_mat = torch.zeros(num_tensor, num_tensor, dtype=torch.float32)\n",
    "  for i in tqdm(range(num_tensor), desc=\"[distance matrix]\"):\n",
    "    for j in range(i+1, num_tensor):\n",
    "      dist = weighted_pqgram_distance(weights, tensors[i], tensors[j])\n",
    "      dist_mat[i][j] = dist\n",
    "      dist_mat[i][j] = dist\n",
    "  return dist_mat\n",
    "\n",
    "\n",
    "def create_pairs_lmnn(data, labels, weights, k):\n",
    "  distances = distance_matrix(data, weights)\n",
    "\n",
    "  positive_pairs = []\n",
    "  negative_pairs = []\n",
    "\n",
    "  for i in range(len(data)):\n",
    "\n",
    "    distances_asc_arg = torch.argsort(distances[i])[1:]\n",
    "\n",
    "    targets = []\n",
    "    impostors = []\n",
    "    label_i = labels[i]\n",
    "    j = 0\n",
    "    while len(targets)<=k:\n",
    "      idx = distances_asc_arg[j]\n",
    "      if labels[idx] == label_i:\n",
    "        targets.append(idx)\n",
    "      else:\n",
    "        impostors.append(idx)\n",
    "      j += 1\n",
    "    \n",
    "    positive_pairs.extend([(data[i], data[j]) for j in targets])\n",
    "    negative_pairs.extend([(data[i], data[j]) for j in impostors])\n",
    "\n",
    "    return positive_pairs, negative_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[distance matrix]: 100%|██████████| 1200/1200 [01:00<00:00, 19.71it/s] \n",
      "/home/yamazoe/.pyenv/versions/3.11.7/envs/env_pq/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[learning]:   7%|▋         | 42/600 [00:00<00:02, 236.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Loss: 66.49757385253906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[distance matrix]: 100%|██████████| 1200/1200 [01:48<00:00, 11.07it/s] \n"
     ]
    }
   ],
   "source": [
    "train_tensors = torch.load(\"data/train_tensors_ja_en_pud.pt\")\n",
    "train_labels = torch.load(\"data/train_labels_ja_en_pud.pt\")\n",
    "\n",
    "margin1 = margin2 = 5.0\n",
    "beta = 1e-4\n",
    "dim = train_tensors[0].size()[0]\n",
    "\n",
    "positive, negative = create_pairs_lmnn(train_tensors, train_labels, weights=torch.ones(dim), k=1)\n",
    "\n",
    "dist_func = WeightedPqgramDistance(dim)\n",
    "criterion = MetricLearingLoss(margin1, margin2, beta)\n",
    "\n",
    "optimizer = optim.Adam(dist_func.parameters(), lr=0.01)\n",
    "\n",
    "num_epoch = 600\n",
    "loss_list = []\n",
    "\n",
    "for epoch in tqdm(range(num_epoch), desc=\"[learning]\"):\n",
    "  optimizer.zero_grad()\n",
    "  loss = criterion(dist_func, positive, negative)\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  loss_list.append(loss.detach().numpy())\n",
    "\n",
    "  if epoch == 0:\n",
    "        print(f'\\nEpoch {epoch+1}, Loss: {loss.item()}')\n",
    "        best_epoch = epoch+1\n",
    "        best_loss = loss.item()\n",
    "      \n",
    "  if epoch in [49, 99, 149, 199, 249, 299, 349, 399, 449, 499, 549]:\n",
    "    positive, negative = create_pairs_lmnn(train_tensors, train_labels, dist_func.weights, k=3)\n",
    "    print(f'\\nEpoch {epoch+1}, Loss: {loss.item()}')\n",
    "  \n",
    "  if loss.item() < best_loss:\n",
    "    best_epoch = epoch+1\n",
    "    best_loss = loss.item()\n",
    "    torch.save(dist_func.state_dict(), 'models/weighted_distance_model_pud_en_ja.pth')\n",
    "\n",
    "print(f'\\nEpoch:{best_epoch},\\nLoss:{best_loss}')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(range(num_epoch),loss_list)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_tensors_path = \"data/train_tensors_en_corpora_EWT_ESL.pt\"\n",
    "train_tensors = torch.load(train_tensors_path)\n",
    "dimension = train_tensors[0].size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8363"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('ABCDEFGHIJKLMNOPQRSTUVWXYZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 10)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "l = reversed(list(range(10)))\n",
    "for i in l:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.4995, 0.6807, 0.8019, 0.0879]),\n",
       " tensor([0.9876, 0.3137, 0.9156, 0.9397]),\n",
       " tensor([0.9568, 0.4890, 0.7837, 0.4539]),\n",
       " tensor([0.0738, 0.6614, 0.8929, 0.0463])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_list = []\n",
    "for _ in range(4):\n",
    "    tensor_list.append(torch.rand(4))\n",
    "tensor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0994, 0.9053, 0.0328, 0.8189])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_key = torch.rand(4)\n",
    "tensor_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76416141, 1.18173742, 0.93515301, 0.6732254 ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_list = []\n",
    "for tensor_i in tensor_list:\n",
    "    distance_list.append(float(torch.dot(tensor_key, tensor_i).detach().numpy()))\n",
    "distance_list = np.array(distance_list)\n",
    "distance_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(distance_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0336, 0.1114]) tensor([0.5541, 0.5390])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.rand(2)\n",
    "t2 = torch.rand(2)\n",
    "print(t1, t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 > t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6080, 0.0500, 0.9096, 0.3938], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.rand(4).cuda()\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.8240, 0.1499, 2.7288, 1.1815], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3*t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(1,1048,1):\n",
    "    k = (402*i)%1049\n",
    "    if k==1:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=23\n",
    "g=2\n",
    "r=6\n",
    "m=3\n",
    "x=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = (g**x)%p\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = (g**r)%p\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = (m*(y**r))%p \n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = (u**x)%p \n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1,p,1):\n",
    "    if (w*i)%p == 1:\n",
    "        w_inv = i\n",
    "w_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element 'dblp' at 0x7f3414516ca0>\n"
     ]
    }
   ],
   "source": [
    "tree = ET.parse(\"tmp/test.xml\")\n",
    "tree = tree.getroot()\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.trees import xml_to_pqTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_gram = xml_to_pqTree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dblp\n",
      "mastersthesis\n",
      "author\n",
      "title\n",
      "year\n",
      "school\n"
     ]
    },
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/env_pq/lib/python3.11/site-packages/graphviz/backend/execute.py:78\u001b[0m, in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m         proc \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/lib/python3.11/subprocess.py:548\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m--> 548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/lib/python3.11/subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/lib/python3.11/subprocess.py:1950\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[0m\n\u001b[1;32m   1949\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1950\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1951\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: PosixPath('dot')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 29\u001b[0m\n\u001b[1;32m     25\u001b[0m             node_id \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     26\u001b[0m     graph\u001b[38;5;241m.\u001b[39mrender()\n\u001b[0;32m---> 29\u001b[0m \u001b[43mtree_visualize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree_gram\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 26\u001b[0m, in \u001b[0;36mtree_visualize\u001b[0;34m(root, FILENAME)\u001b[0m\n\u001b[1;32m     24\u001b[0m         graph\u001b[38;5;241m.\u001b[39medge(\u001b[38;5;28mstr\u001b[39m(parent_id), \u001b[38;5;28mstr\u001b[39m(node_id))\n\u001b[1;32m     25\u001b[0m         node_id \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 26\u001b[0m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/env_pq/lib/python3.11/site-packages/graphviz/_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     wanted \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    163\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m    164\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be reduced\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    165\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m positional args\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    166\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    167\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as keyword arg(s)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    168\u001b[0m                   stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    169\u001b[0m                   category\u001b[38;5;241m=\u001b[39mcategory)\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/env_pq/lib/python3.11/site-packages/graphviz/rendering.py:122\u001b[0m, in \u001b[0;36mRender.render\u001b[0;34m(self, filename, directory, view, cleanup, format, renderer, formatter, neato_no_op, quiet, quiet_view, outfile, engine, raise_if_result_exists, overwrite_source)\u001b[0m\n\u001b[1;32m    118\u001b[0m filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave(filename, directory\u001b[38;5;241m=\u001b[39mdirectory, skip_existing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    120\u001b[0m args\u001b[38;5;241m.\u001b[39mappend(filepath)\n\u001b[0;32m--> 122\u001b[0m rendered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cleanup:\n\u001b[1;32m    125\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelete \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m, filepath)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/env_pq/lib/python3.11/site-packages/graphviz/_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     wanted \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    163\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m    164\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be reduced\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    165\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m positional args\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    166\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    167\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as keyword arg(s)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    168\u001b[0m                   stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    169\u001b[0m                   category\u001b[38;5;241m=\u001b[39mcategory)\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/env_pq/lib/python3.11/site-packages/graphviz/backend/rendering.py:326\u001b[0m, in \u001b[0;36mrender\u001b[0;34m(engine, format, filepath, renderer, formatter, neato_no_op, quiet, outfile, raise_if_result_exists, overwrite_filepath)\u001b[0m\n\u001b[1;32m    322\u001b[0m cmd \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m filepath \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwork around pytype false alarm\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 326\u001b[0m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mfspath(outfile)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/env_pq/lib/python3.11/site-packages/graphviz/backend/execute.py:81\u001b[0m, in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m errno\u001b[38;5;241m.\u001b[39mENOENT:\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ExecutableNotFound(cmd) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet \u001b[38;5;129;01mand\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mstderr:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m: failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "from graphviz import Graph\n",
    "\n",
    "\n",
    "def tree_visualize(root, FILENAME=\"tmp_tree\"):\n",
    "    \"\"\"\n",
    "    木構造の幅優先探索を利用して木を描画する\n",
    "    \"\"\"\n",
    "    queue = deque([root])\n",
    "    graph = Graph()\n",
    "    graph.attr(\"node\", shape=\"circle\")\n",
    "    node_id = 1\n",
    "    graph.node(str(node_id), root.label)\n",
    "    node_id += 1\n",
    "    parent_id = 0\n",
    "    while queue:\n",
    "        node = queue.popleft()\n",
    "        print(node.label)  # ノードのラベルを出力\n",
    "        parent_id += 1\n",
    "\n",
    "        for child in node.children:\n",
    "            queue.append(child)\n",
    "            graph.node(str(node_id), child.label)\n",
    "            graph.edge(str(parent_id), str(node_id))\n",
    "            node_id += 1\n",
    "    graph.render()\n",
    "\n",
    "\n",
    "tree_visualize(tree_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from scripts import create_strings\n",
    "\n",
    "trees = create_strings.generate_binaries(3, 2, 5)\n",
    "print(trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clearnlp.converter import SubprocessConverter\n",
    "\n",
    "converter = SubprocessConverter()\n",
    "trees = [\"(ROOT (S (NP (DT The) (NN cat)) (VP (VBD sat) (PP (IN on) (NP (DT the) (NN mat))))))\"]\n",
    "converted_trees = converter.convert_trees(trees)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tThe\tthe\tDT\t_\t2\tdet\t_\t_\t_\n",
      "2\tcat\tcat\tNN\t_\t3\tdep\t_\t_\t_\n",
      "3\tsat\tsit\tVBD\t_\t0\troot\t_\t_\t_\n",
      "4\ton\ton\tIN\t_\t3\tprep\t_\t_\t_\n",
      "5\tthe\tthe\tDT\t_\t6\tdet\t_\t_\t_\n",
      "6\tmat\tmat\tNN\t_\t4\tpobj\t_\t_\t_\n"
     ]
    }
   ],
   "source": [
    "for word in converted_trees:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0816],\n",
       "        [0.0095],\n",
       "        [0.7857],\n",
       "        [0.4315]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand((4,1)) \n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0095])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_val = t.min(dim=0).values\n",
    "min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7857])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_val = t.max(dim=0).values\n",
    "max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0929],\n",
       "        [0.0000],\n",
       "        [1.0000],\n",
       "        [0.5436]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_normalized = (t-min_val)/(max_val-min_val)\n",
    "t_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6876],\n",
       "        [-0.8895],\n",
       "        [ 1.2847],\n",
       "        [ 0.2925]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = t.mean(dim=0)\n",
    "std = t.std(dim=0)\n",
    "\n",
    "(t-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
